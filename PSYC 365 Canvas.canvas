{
  "nodes": [
    {
      "id": "bc33b64437a030a2",
      "type": "group",
      "styleAttributes": {},
      "x": -161,
      "y": -340,
      "width": 1980,
      "height": 2740,
      "label": "Studying the Brain"
    },
    {
      "id": "304311b0cb7be1c7",
      "type": "group",
      "styleAttributes": {},
      "x": 1920,
      "y": 660,
      "width": 1980,
      "height": 1380,
      "label": "Vision"
    },
    {
      "id": "91974b28b540693c",
      "type": "text",
      "text": "\n**SHORT ANSWER QUESTION**  \nAnswer the following based on the paper we read by Harada et al., 2020, which used fMRI to examine  \nquestions related to face perception and race/culture, as well what you know from lecture material  \nabout the paper (30 points).  \n\n- **A. What was the big-picture question that motivated the study? (1 pt total)**  \n\n- **B. Background (6 pts total)**  \n\t- *I. Describe one thing that previous research, described in the Introduction of the paper, has taught us about the influence of culture on responses to facial emotion and one set of findings described in the paper that support that knowledge. Your answer for the  second part of this question (about the set of findings) should elaborate on your answer  in the first part of this question. (4 pts)* \n\t- Previous studies have shown in-group affects on bilateral amygdala response. \n\t- *II. What two self-construal styles have been identified by cultural psychologists and what are the main characteristics of each? (2 pts)*  \n- **C. Research Questions and Hypotheses (3 pts total)**  \n\t- *I. What was the main research question? (1 pt)*  \n\t- How do Japanese bicultural individuals (raised in individualistic culture but with connections to collectivistic) compare to Native Japanese (collectivism) in amygdala response to racial in and out group faces? (\"That is to say, what neural modulation in the amygdala would be observed in Japanese-American individuals, who are very familiar with Caucasian-Americans’ faces while they have a similarity of physical appearance to native Japanese people, when they were shown facial emotional ex- pressions of Caucasians and Japanese?\")\n\t- *II. What were two hypotheses put forward by the authors? (2 pts)*  \n\t-  Bicultural (Japanese American) individuals would show greater amygdala response to Japanese faces than Caucasian Americans, and \"collectivistic tendencies would be related to neural responses of intergroup negative facial expression.\"\n- **D. Methods (2 pts total)**  \n\t- *I. How did they define group membership? (1 pt)*  \n\t- Japanese-Americans were born and/or raised from a young age in America, either first-generation or second-generation. Japanese Natives were born and raised in Japan, and Caucasian Americans. In-group for Japanese Americans was racial in group ie. Japanese. \n\t- *II. What was the purpose of the shape stimuli? (1 pt)*  \n\t- The shape stimuli serve as a control task for a \"relatively low-level cognitive process\"  \n- **E. Results (4 pts total)**  \n\t- *I. What was the main pattern of findings for the amygdala? What patterns of brain  activity reflected the “cultural in-group effect?” (2 pts)*  \n\t- There was a significant in-group effect observed in the bilateral amygdala when comparing Native Japanese group with Caucasian-American group. Native Japanese participants showed larger neural responses itn the bilateral amygdala to Japanese faces than Caucasian-Americans did. \n\t- Caucasian-American and Japanese participants showed the highest amygdala activities to negative faces of the same cultural and racial members (i.e. in-group members) and the lowest amygdala activities to those of the different cultural and racial group members\n\t- Japanese-American participants showed neural responses in between the JN and CA groups. \n\t- *II. What pattern of brain activity did they find in one particular group of participants when  they looked at the whole brain? (2 pts)*  \n\t-  Japanese-American participants showed greater activities in the right ventral prefrontal cortex, posterior cingulate cortex extending to precueus and right superior frontal gyrus during processing of negative facial expressions of Japanese than Caucasian-American participants did\n- **F. Discussion (4 pts total)**  \n\t- *I. How do they interpret the midline cortical findings observed in one particular group? (2  pts)*  \n\t- Likely reflects greater informational demands of self-relevant memory, because their recognition of their racial identity might be automatically strengthened when negative facial expression of racially in-group members was presented.\n\t- *II. Was their hypothesis about individual differences supported? Why or why not? (2 pts)*  \n\t- \"This result indicates that bicultural individuals respond to negative facial expressions of members from the both cultural groups with slightly attenuated extent as compared to monocultural individuals. We hypothesized that JA individuals would show large amygdala responses to Caucasian negative faces as the same extent as CA individuals would if the in-group bias was due to familiarity of faces learned in their daily life, while they would show large amygdala response to Japanese negative faces as the same extent as JP individuals would if the in-group bias was simply due to their racial identity. The results in the current study did not support either hypothesis\"\n\t- \"Although this way might not necessarily eliminate the possibility of remaining variations, it would be still a possible solution and even more useful way by combining with an additional and detailed reliability test such as a ROI analysis for target brain regions that we have done in the current study. In the current study, we excluded the temporal and occipital regions from the analyses only when directly comparing the different facilities, and furthermore confirmed that there was no significant difference of neural activities in the hypothesized regions, that is the bilateral amygdala, in our prior reliability test. Hence, variation in scanner-site performance is not a likely explanation for the variability in the neural activation we observed in the current study.\"\n- **G. Conclusions and limitations (6 pts total)**  \n\t- *I. How do they describe the overall meaning and importance of the results? (2 pts)*  \n\t- \"Our results show that neural responses in the bilateral amygdala reflected both of in-group biases based on ones’ racial identities and cultural practices, such as ones’ collectivistic tendencies, irrespective of participants’ cultures.\"\n\t- \"Our results demonstrate that neural responses during the processing of emotional faces could be modulated by different social factors, such as cultural practice and racial identity, and furthermore cultural and racial influences are interlaced especially in bicultural individuals such as Japanese-Americans in the current study.\"\n\t- *II. List TWO limitations of the study and explain why they are limitations. (4 pts)*  \n\t- One limitation of this study involves the generalizability of our findings, as the results were based on only facial expressions of fear and anger.\n\t- There might be another limitation in the current study, that is a possible variation in the scanner performance between the two facilities which may have led to variations in the neural activation patterns across the two different scanning sites.\n- **H. In YOUR opinion (4 pts total)**  \n\t- *I. What are the larger cultural or societal implications of these findings? Do you agree  with the authors’ conclusions? Why or why not? What do you think is important that  they didn’t think of? (4 pts)*",
      "styleAttributes": {},
      "x": -2240,
      "y": 1058,
      "width": 720,
      "height": 2075
    },
    {
      "id": "f1e6e9121982dea9",
      "type": "text",
      "text": "",
      "styleAttributes": {},
      "x": -2180,
      "y": 3118,
      "width": 660,
      "height": 880
    },
    {
      "id": "3cc2c3c0a9a96bc2",
      "type": "file",
      "file": "W2024 Files/Screenshot 2025-02-03 at 10.21.09 AM.png",
      "styleAttributes": {},
      "x": 729,
      "y": 427,
      "width": 991,
      "height": 501
    },
    {
      "id": "4add580745375d7a",
      "type": "text",
      "text": "PET:\n- Tracers, invasive\n- Poor temporal res.",
      "styleAttributes": {},
      "x": 380,
      "y": 720,
      "width": 260,
      "height": 120
    },
    {
      "id": "eb98624574c9f380",
      "type": "text",
      "text": "MRI:\n- Protons in H atms resonate when mag field direction changes\n- Diff tissues produce diff imgs\n",
      "styleAttributes": {},
      "x": 380,
      "y": 880,
      "width": 260,
      "height": 178
    },
    {
      "id": "70c1126eda36aa33",
      "type": "text",
      "text": "fMRI: \n- Diff in activity btwn groups\n- Measures BOLD",
      "styleAttributes": {},
      "x": 380,
      "y": 1080,
      "width": 260,
      "height": 99
    },
    {
      "id": "eb4c88ca83138caa",
      "type": "text",
      "text": "ECoG-Stereo EEG: \n- Intracranial \n- V. invasive; epilepsy studies",
      "styleAttributes": {},
      "x": 380,
      "y": 580,
      "width": 260,
      "height": 99
    },
    {
      "id": "d4d6d750112884fb",
      "type": "text",
      "text": "Dependent var. = BOLD response\n- Statistics → map of activity, colors indicating stat. threshold ",
      "styleAttributes": {},
      "x": 760,
      "y": 1080,
      "width": 320,
      "height": 96
    },
    {
      "id": "5626bf81ea0feefe",
      "type": "text",
      "text": "Encoding: \n- Goal = brain mapping, disc. regions responsible for basic prcs\n- ID regions active during exp. conds.\n- Look at avg actv for each individ vowel across trials in each cond and measure diff\n\nBut depends on pattern of high/low activation instead of in individ? → representational approach",
      "styleAttributes": {},
      "x": 1280,
      "y": 1130,
      "width": 520,
      "height": 224
    },
    {
      "id": "274630e3133431ab",
      "type": "text",
      "text": "Event-related potentials (ERPs):\n- Avg. EEG signal following {stim/response}\n- Components linked to specf processes\n- *When, not where*\n\nFrequency domain analyses:\n- Decomposes EEG signal into diff freqs\n- Shows synchrony over distant regions - study networks",
      "styleAttributes": {},
      "x": 760,
      "y": 121,
      "width": 520,
      "height": 220
    },
    {
      "id": "4e54c9a4502b3dc3",
      "type": "text",
      "text": "1) Encoding: Standard, \"brain mapping → use stim or exp. task and measure activity\"\n2) Decoding: Look at brain act. and predict what stim/cogn. prcs produced it\n ",
      "styleAttributes": {},
      "x": 760,
      "y": 1260,
      "width": 320,
      "height": 160
    },
    {
      "id": "ad8a03fca1847400",
      "type": "text",
      "text": "Lesion network mapping: \n- Diff locations linked to same deficit → find network they comprise",
      "styleAttributes": {},
      "x": 320,
      "y": -318,
      "width": 260,
      "height": 122
    },
    {
      "id": "01023f319a1a824d",
      "type": "text",
      "text": "2 kinds of \"**mechanistic insigh**t\": \n- What is captured by mechanism (cell, population, network)\n- Ability of each method to record role (purely observational, manipulate process/task, manipulate brain)",
      "styleAttributes": {},
      "x": 290,
      "y": -92,
      "width": 320,
      "height": 180
    },
    {
      "id": "3e2080c6f6ef17a8",
      "type": "text",
      "text": "MEG:\n- Pop. of neurons\n- Good temporal res\n- Magnetic fluctuations caused by electrical activity\n- Better spatial res since signal not distorted",
      "styleAttributes": {},
      "x": 380,
      "y": 355,
      "width": 260,
      "height": 200
    },
    {
      "id": "149112c8b79929e8",
      "type": "text",
      "text": "EEG: \n- Measures electrical activity outside columns of cortical cells\n- Poor spatial res. \n- Good temporal res",
      "styleAttributes": {},
      "x": 380,
      "y": 140,
      "width": 260,
      "height": 180
    },
    {
      "id": "fc8356fdb4b4318c",
      "type": "text",
      "text": "Measuring connectivity: \n1) Anatomical/Structural connectivity - DTI/myelin imaging\n2) Functional connectivity - correlation in act. btwn BOLD in diff areas",
      "styleAttributes": {},
      "x": 60,
      "y": 928,
      "width": 260,
      "height": 200
    },
    {
      "id": "ef6ccd14871cc654",
      "type": "text",
      "text": "Lesion studies:\n- Causal \n- behaviors & cogn. processes",
      "styleAttributes": {},
      "x": -40,
      "y": -320,
      "width": 260,
      "height": 125
    },
    {
      "id": "af80c58975a86b48",
      "type": "text",
      "text": "**Poldrack and Farah, 2015**\n- Mechanism =  \"causal chain of events that result in the realization of a function.\"\n- Methods which provide little insight: \n\t- \"Methods that exploit naturally occurring variation by observing the strength of association between individual differences in brain function and behaviour. Analysis of relationships between behavioural traits, genes, brain structure, and brain function exemplify this approach.\"",
      "styleAttributes": {},
      "x": 680,
      "y": -317,
      "width": 440,
      "height": 282
    },
    {
      "id": "bc5bba5490c9e6a9",
      "type": "text",
      "text": "**P & F**: Defending functional neuroimaging\n- We can infer that brain activity reliably elicited by task was caused by task BUT can't infer that brain is causally responsble",
      "styleAttributes": {},
      "x": -120,
      "y": 455,
      "width": 360,
      "height": 140
    },
    {
      "id": "75f367c0d68d68e3",
      "type": "text",
      "text": "Neuromodulation - TMS & TES: \n- Causal \n- Inhibiting/exciting neurons \n- behaviors & cogn. processes",
      "styleAttributes": {},
      "x": -40,
      "y": -79,
      "width": 260,
      "height": 154
    },
    {
      "id": "4af78d16073a1676",
      "type": "text",
      "text": "**P & F**: \"Workhorse of cognitive neuroscience\"\n",
      "styleAttributes": {},
      "x": 0,
      "y": 1200,
      "width": 360,
      "height": 60
    },
    {
      "id": "e508211250760542",
      "type": "text",
      "text": "Early visual areas ie V1: no suppression, same HDR = treat diff sizes as diff obj. \n\nAnterior LOC: HDR suppression = treat diff sizes as same obj",
      "styleAttributes": {},
      "x": 3530,
      "y": 1480,
      "width": 300,
      "height": 146
    },
    {
      "id": "f231a61ba0782e9e",
      "type": "text",
      "text": "fMRIs have shown (w/ encoding): \n- Response preference to features → whole obj. from V1 → LOC\n- Size + viewpoint invariance later in visual stream",
      "styleAttributes": {},
      "x": 2380,
      "y": 1660,
      "width": 260,
      "height": 200
    },
    {
      "id": "d4e8864a22df9e35",
      "type": "text",
      "text": "Computer vision: CNNs",
      "styleAttributes": {},
      "x": 2380,
      "y": 1960,
      "width": 260,
      "height": 60
    },
    {
      "id": "f3dacb927a743b2a",
      "type": "text",
      "text": "Similar to visual stream, fragmented → whole",
      "styleAttributes": {},
      "x": 2760,
      "y": 1960,
      "width": 260,
      "height": 60
    },
    {
      "id": "c836baff3953daa3",
      "type": "text",
      "text": "V1 neurons see obj. from just 1 view, higher order reg. collect info, match to mental representations of obj. from prior/childhood exp. ",
      "styleAttributes": {},
      "x": 3530,
      "y": 1666,
      "width": 300,
      "height": 103
    },
    {
      "id": "8053bc20107f8402",
      "type": "text",
      "text": "Feedforward bottom-up feature-based sweep: \n- V1 → IT\n- Bottom-up - simple → complex\n- Feature-based - individ. elements combine to create complete rep.\n\nAt IT: match obj. to \"mental template\"",
      "styleAttributes": {},
      "x": 2380,
      "y": 1050,
      "width": 260,
      "height": 296
    },
    {
      "id": "3ffcd312a5f87e67",
      "type": "text",
      "text": "Grill-Spector fMRI study: \n- BOLD response to diff. degrees of scrambled images\n\nResults: \n- V1 prefers scrambles\n- V4v prefers partial (simple/localized features)\n- LOC prefers whole obj. \n\nTakeaway: consistent w/ feedforward model, regions from \"bottom\" (beginning of stream/V1) to \"top\" respond to more fragmented → more \"whole\" imgs accordingly ",
      "styleAttributes": {},
      "x": 2730,
      "y": 1102,
      "width": 410,
      "height": 347
    },
    {
      "id": "3749b1bef816fd0a",
      "type": "text",
      "text": "Adaptive suppression: \n- Size inv.t: If size inv.t, neurons should treat diff sizes of obj. as same → suppression of hemodynamic response (HDR)\n\t- Not size inv.t → no suppression\n\t- V1 not inv.t | Ant. LOC inv.t\n- Viewpoint inv.t\n\t- EV areas and posterior LOC: no suppression, not viewpoint inv.t \n\t- Ant. LOC: suppression, viewpoint inv.t",
      "styleAttributes": {},
      "x": 3080,
      "y": 1480,
      "width": 380,
      "height": 289
    },
    {
      "id": "e480d1f3b7dcf4ba",
      "type": "text",
      "text": "Bowers et al",
      "styleAttributes": {},
      "x": 3100,
      "y": 1930,
      "width": 260,
      "height": 60,
      "color": "1"
    },
    {
      "id": "e8f42e3eb8d62261",
      "type": "text",
      "text": "LOC = IDing obj. ",
      "styleAttributes": {},
      "x": 2730,
      "y": 990,
      "width": 160,
      "height": 60
    },
    {
      "id": "807b4f1bb6c92d3d",
      "type": "text",
      "text": "Challenges to obj. recognition:\n1) Obj. can be occluded\n2) Diff. in size/distance\n3) Obj. can look diff from diff angles",
      "styleAttributes": {},
      "x": 2380,
      "y": 1480,
      "width": 260,
      "height": 154
    },
    {
      "id": "fe040844129829f7",
      "type": "text",
      "text": "Size invariance: recognize obj. when diff size (perspective)",
      "styleAttributes": {},
      "x": 2730,
      "y": 1480,
      "width": 260,
      "height": 60
    },
    {
      "id": "773a44c709838458",
      "type": "text",
      "text": "Viewpoint invariance: recognize obj. from diff POV",
      "styleAttributes": {},
      "x": 2730,
      "y": 1595,
      "width": 260,
      "height": 60
    },
    {
      "id": "90da43c1b20936e0",
      "type": "text",
      "text": "Dorsal stream = parietal = where/how\n\nVentral = temporal = what",
      "styleAttributes": {},
      "x": 2730,
      "y": 776,
      "width": 300,
      "height": 100
    },
    {
      "id": "a038cfb4758cf553",
      "type": "text",
      "text": "Apperceptive agnosia: \n- Can't recognize bear standing in front of you \n- Can't name obj. ",
      "styleAttributes": {},
      "x": 3420,
      "y": 838,
      "width": 260,
      "height": 120
    },
    {
      "id": "3c0201ca53ece704",
      "type": "text",
      "text": "Milner & Goodale: Pt. DF\n- Vis. form agnosia: ventral stream disrupted\n- M&G argue that both streams have same info but diff. prcs. - parallel processing ",
      "styleAttributes": {},
      "x": 3040,
      "y": 876,
      "width": 260,
      "height": 204
    },
    {
      "id": "52a4d959c7fc2ef7",
      "type": "text",
      "text": "Associative agnosia\n- Can't recognize chair from diff angles\n- Can't see forest for trees",
      "styleAttributes": {},
      "x": 3420,
      "y": 1042,
      "width": 260,
      "height": 120
    },
    {
      "id": "4be4cceddaa70020",
      "type": "text",
      "text": "** Check if correct",
      "styleAttributes": {},
      "x": 3620,
      "y": 760,
      "width": 260,
      "height": 60,
      "color": "1"
    },
    {
      "id": "438546c185e63f58",
      "type": "file",
      "file": "W2024 Files/Screenshot 2025-02-03 at 10.51.17 AM.png",
      "styleAttributes": {},
      "x": 1940,
      "y": 680,
      "width": 391,
      "height": 400
    },
    {
      "id": "6bb2fe2befba6dbc",
      "type": "text",
      "text": "Light → lens → retina → optic nerve → LGN → V1",
      "styleAttributes": {},
      "x": 2380,
      "y": 680,
      "width": 260,
      "height": 60
    },
    {
      "id": "8e497a75399e7ba4",
      "type": "text",
      "text": "**Feedforward**:\n- Receptive field size increases further down visual stream - more info integrated\n- V1 has unintegrated fragments, → LOC, IT downstream do integration into shapes, obj.",
      "styleAttributes": {},
      "x": 2380,
      "y": 760,
      "width": 260,
      "height": 256
    },
    {
      "id": "30eb0ad1bc10d0d1",
      "type": "text",
      "text": "- Structural connectivity: DTI\n- Functional connectivity: correlated activity as observed on an fMRI ",
      "styleAttributes": {},
      "x": 760,
      "y": 1460,
      "width": 320,
      "height": 100
    },
    {
      "id": "dd18d41495ada93f",
      "type": "text",
      "text": "Intrinsic (arising spontaneously) networks:\n- Activity is correlated at rest \n- Identified with resting-state fMRI - in **(P & F)**\n\n*Canonical* Intrinsic Networks: observed very commonly at rest ",
      "styleAttributes": {},
      "x": 760,
      "y": 1602,
      "width": 320,
      "height": 222
    },
    {
      "id": "8d54b99ec61f095e",
      "type": "text",
      "text": "Decoding: \n- Multivoxel decoding approach - MVPA/RSA\n- Goal: \"mind reading\"\n- MVPA: How do patterns of activation represent mental cat./states? \n- RSA: How similar are brain rep. to each other?/What does brain group together?",
      "styleAttributes": {},
      "x": 1280,
      "y": 1419,
      "width": 520,
      "height": 182
    },
    {
      "id": "3ce924f2d1f1d928",
      "type": "text",
      "text": "- [[Class3_365_2025.pdf]]\n- [[Class4_365_2025_notes.pdf]]\n- [[Class5_365_2025_notes.pdf]]\n- [[Class6_365_2025_2_notes.pdf]]\n- [[Class7_365_2025_notes.pdf]]\n- [[Class8_365_2025_review_revised.pdf]]",
      "styleAttributes": {},
      "x": -700,
      "y": -280,
      "width": 460,
      "height": 200
    },
    {
      "id": "88fb75496a6985d7",
      "type": "text",
      "text": "Kinds of brain scans: \n- EEG (pop/network)\n- MEG (pop/network)\n- ECoG/Stero EEG (cell/pop)\n- PET (molecular)\n- MRI/DTI\n- fMRI",
      "styleAttributes": {},
      "x": -120,
      "y": 140,
      "width": 260,
      "height": 200
    }
  ],
  "edges": [
    {
      "id": "8cbb8bcf90f8e1ea",
      "styleAttributes": {},
      "fromNode": "ef6ccd14871cc654",
      "fromSide": "right",
      "toNode": "ad8a03fca1847400",
      "toSide": "left"
    },
    {
      "id": "adb7c78a7ce17dae",
      "styleAttributes": {},
      "fromNode": "ad8a03fca1847400",
      "fromSide": "bottom",
      "toNode": "01023f319a1a824d",
      "toSide": "top"
    },
    {
      "id": "ad51b373fe01c606",
      "styleAttributes": {},
      "fromNode": "75f367c0d68d68e3",
      "fromSide": "right",
      "toNode": "01023f319a1a824d",
      "toSide": "left"
    },
    {
      "id": "0df1b82a461c6948",
      "styleAttributes": {},
      "fromNode": "149112c8b79929e8",
      "fromSide": "right",
      "toNode": "274630e3133431ab",
      "toSide": "left"
    },
    {
      "id": "94d982c5bec23587",
      "styleAttributes": {},
      "fromNode": "70c1126eda36aa33",
      "fromSide": "right",
      "toNode": "d4d6d750112884fb",
      "toSide": "left"
    },
    {
      "id": "538b83ab4e261ca6",
      "styleAttributes": {},
      "fromNode": "70c1126eda36aa33",
      "fromSide": "bottom",
      "toNode": "4e54c9a4502b3dc3",
      "toSide": "left"
    },
    {
      "id": "53214d3efe6d671a",
      "styleAttributes": {},
      "fromNode": "4e54c9a4502b3dc3",
      "fromSide": "right",
      "toNode": "5626bf81ea0feefe",
      "toSide": "left"
    },
    {
      "id": "4ea69d0b94b5a1b7",
      "styleAttributes": {},
      "fromNode": "4e54c9a4502b3dc3",
      "fromSide": "right",
      "toNode": "8d54b99ec61f095e",
      "toSide": "left"
    },
    {
      "id": "a0f16663cbac256b",
      "styleAttributes": {},
      "fromNode": "90da43c1b20936e0",
      "fromSide": "bottom",
      "toNode": "3c0201ca53ece704",
      "toSide": "left"
    },
    {
      "id": "9dc3ee0a457cef11",
      "styleAttributes": {},
      "fromNode": "8e497a75399e7ba4",
      "fromSide": "right",
      "toNode": "e8f42e3eb8d62261",
      "toSide": "left"
    },
    {
      "id": "12d48caa22d4c0e0",
      "styleAttributes": {},
      "fromNode": "3c0201ca53ece704",
      "fromSide": "right",
      "toNode": "a038cfb4758cf553",
      "toSide": "left"
    },
    {
      "id": "8807af29a85bec81",
      "styleAttributes": {},
      "fromNode": "3c0201ca53ece704",
      "fromSide": "right",
      "toNode": "52a4d959c7fc2ef7",
      "toSide": "left"
    },
    {
      "id": "3cd4621034f25d99",
      "styleAttributes": {},
      "fromNode": "8e497a75399e7ba4",
      "fromSide": "bottom",
      "toNode": "8053bc20107f8402",
      "toSide": "top"
    },
    {
      "id": "ce4c328f113e32f9",
      "styleAttributes": {},
      "fromNode": "8053bc20107f8402",
      "fromSide": "right",
      "toNode": "3ffcd312a5f87e67",
      "toSide": "left"
    },
    {
      "id": "62cf5d963783f7f7",
      "styleAttributes": {},
      "fromNode": "807b4f1bb6c92d3d",
      "fromSide": "right",
      "toNode": "fe040844129829f7",
      "toSide": "left"
    },
    {
      "id": "ea2e069874d35c08",
      "styleAttributes": {},
      "fromNode": "807b4f1bb6c92d3d",
      "fromSide": "right",
      "toNode": "773a44c709838458",
      "toSide": "left"
    },
    {
      "id": "172a698b6acf1a48",
      "styleAttributes": {},
      "fromNode": "fe040844129829f7",
      "fromSide": "right",
      "toNode": "3749b1bef816fd0a",
      "toSide": "left"
    },
    {
      "id": "9a9248bc5a70b2fc",
      "styleAttributes": {},
      "fromNode": "773a44c709838458",
      "fromSide": "right",
      "toNode": "3749b1bef816fd0a",
      "toSide": "left"
    },
    {
      "id": "9eb703b27e19a852",
      "styleAttributes": {},
      "fromNode": "3749b1bef816fd0a",
      "fromSide": "right",
      "toNode": "e508211250760542",
      "toSide": "left"
    },
    {
      "id": "e29c77bd96a4f322",
      "styleAttributes": {},
      "fromNode": "807b4f1bb6c92d3d",
      "fromSide": "bottom",
      "toNode": "f231a61ba0782e9e",
      "toSide": "top"
    },
    {
      "id": "7656483adbf27b34",
      "styleAttributes": {},
      "fromNode": "3749b1bef816fd0a",
      "fromSide": "right",
      "toNode": "c836baff3953daa3",
      "toSide": "left"
    },
    {
      "id": "72049ed8866dac3b",
      "styleAttributes": {},
      "fromNode": "d4e8864a22df9e35",
      "fromSide": "right",
      "toNode": "f3dacb927a743b2a",
      "toSide": "left"
    },
    {
      "id": "2f07221474a88629",
      "styleAttributes": {},
      "fromNode": "af80c58975a86b48",
      "fromSide": "left",
      "toNode": "01023f319a1a824d",
      "toSide": "right"
    },
    {
      "id": "33ae96b728629302",
      "styleAttributes": {},
      "fromNode": "88fb75496a6985d7",
      "fromSide": "bottom",
      "toNode": "bc5bba5490c9e6a9",
      "toSide": "top"
    },
    {
      "id": "c0ae9b46d46b8f0d",
      "styleAttributes": {},
      "fromNode": "4af78d16073a1676",
      "fromSide": "right",
      "toNode": "70c1126eda36aa33",
      "toSide": "left"
    },
    {
      "id": "c60073bef77a9d2b",
      "styleAttributes": {},
      "fromNode": "8d54b99ec61f095e",
      "fromSide": "left",
      "toNode": "30eb0ad1bc10d0d1",
      "toSide": "right"
    },
    {
      "id": "336b76d46cb03cd0",
      "styleAttributes": {},
      "fromNode": "30eb0ad1bc10d0d1",
      "fromSide": "bottom",
      "toNode": "dd18d41495ada93f",
      "toSide": "top"
    }
  ],
  "metadata": {}
}