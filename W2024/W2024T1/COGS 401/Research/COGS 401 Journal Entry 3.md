My area of interest is the psychology and philosophy of perception of the self and of others. I found some very interesting psychological research for the previous journals, which I didnâ€™t expect to tackle the kind of philosophical interests I have. The different dimensions of self-knowledge I think are very interesting to consider, although by the definitions I read about it seems I'm most interested in interpersonal self knowledge, self concept, and the extended self. 

For my 402 project, I have been planning on doing an art installation. I'm a visual arts minor and I think it would be very interesting for me to pursue the intersection of my major and minor. I've talked to Chris Mole about this and he has given me the go-ahead, as well as some preliminary leads on who my supervisor could be. I've also talked to several professors, the UBC New Media technician, and some local artists, but it's been difficult finding someone who has the time and is capable. I've had 3-4 people say they would like to but are not able to dedicate the time, or are not allowed in their contract. So, I'm considering getting in contact with professors at other universities, since they are in theory paid to do student supervisory work and so I think I have a better chance convincing them to supervise me.

The components of my project are definitely still uncertain, but I'm planning on having a machine learning component, a projected component, and an algorithmic and live responsive visual. I started learning Touch Designer, a program to create this kind of installation, over the summer, and I'm currently doing an installation project for an open studio visual arts class. Touch Designer has a lot of different software supports and integration, including Google's machine learning model MediaPipe, which I'm using in my project. My final 402 project will have an algorithm that I have built and trained myself in addition to MediaPipe, I'm not cheating! MediaPipe allows me to use a regular camera as a motion capture (mocap) program, so I can convert different facial expressions, hand gestures, or poses into real time data which can be fed first into my machine learning algorithm and then used to transform the visuals. 

The point of this project is to explore human and computer interaction, as well as to create a facsimile of a human brain. Because the installation responds to movement, but does not mirror or behave predictably, it will feel like an agent. This was something I kind of felt intuitively but is actually expressed in more technical detail in one of the psychology papers I read. The machine learning portion of the installation will allow for actual "social" learning, where it can "understand" the people standing in the room. Because it's not recording personal information, just data points of shoulders, eyebrows, hands etc. and doesn't store video, I hope it wont feel like surveillance nor like I'm playing god, rather that it's a creature or being to be interacted with. Conceptually, the "black box" problem maps onto our understanding of other people's minds as well, which I like. 