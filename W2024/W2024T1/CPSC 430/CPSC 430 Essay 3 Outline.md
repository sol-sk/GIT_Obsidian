
emtngood;nicelies&duty–irrtnls!;insprble|biasinsprble+anthrocntrc,ncssry|countr:purelyratnlstiflesprogress

Morality is a human invention; all moral calculus is defined by human knowledge and reasoning. We may create tools that mitigate biases, error, or emotional judgement, but we can never completely sever ourselves from the rules we create or algorithms we design. 

Moral decisions, whether or not they are made in the spur of the moment or deliberated on and stepped out logically, are influenced by irrationality. This is not always a negative; emotional intuitions can help us design better ethical guidelines. For instance, with Kant's categorical imperative, we understand that "never lie" is not a viable "pure" moral rule because it would upset the people around us and negatively impact our relationships. An "innate sense of duty" is also difficult to rationalize or quantify–yet it is valuable in producing ethical behavior. Whether or not they cloud our judgement, emotion and instinct cannot be separated from argumentation, even in the most contained logical setting. Our instincts, desires, and experiences are valuable information, even if they are not purely rational; we cannot separate ourselves–or the algorithms we design–from our humanity. 

Like emotion and instinct, irrational biases influence our thinking and behavior. Whether it favors ourselves, our ingroup, our country, or our species, bias is inseparable from cognition. Even after mitigating interpersonal biases, virtually any ethical theory will favor humanity above the environment and non-human species. Some would argue this is rational on the basis of our higher cognitive capacity; but this premise is still selecting for our own species-specific traits. If a perfectly ethical algorithm dictated that the most ethical decision was to remove humanity for the natural world's benefit, we–for good reason–would not listen. Even if this were a flaw, certain irrationalities are necessary for a system designed by and for humanity. 

A counter-argument could be made that if we can draw out only the essential components of a scenario, and use the most democratic process to average out biases, we could remove irrationality from ethical analyses. Here, the word "purely" is crucial; the definitive nature of a purely rational decision lends a rigidity that stifles debate and philosophical progress. If a purely rational decision has been made, there exists no better decision. If we were able to make purely rational decisions, there would never be a need to question them. For this reason, it is not only inherent, but beneficial that human irrationality–emotion, instinct, even bias–is inseparable from moral decisions.  






