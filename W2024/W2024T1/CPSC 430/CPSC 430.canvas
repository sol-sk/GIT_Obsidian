{
  "nodes": [
    {
      "id": "928d78e5eaf41007",
      "type": "group",
      "styleAttributes": {},
      "x": -1240,
      "y": 1560,
      "width": 3920,
      "height": 1880,
      "label": "Week 2"
    },
    {
      "id": "102fd1210a3f2db4",
      "type": "group",
      "styleAttributes": {},
      "x": -800,
      "y": 81,
      "width": 3640,
      "height": 1399,
      "label": "Week 1"
    },
    {
      "id": "0eb7dbef99033b68",
      "type": "group",
      "styleAttributes": {},
      "x": -1160,
      "y": 3560,
      "width": 2689,
      "height": 897,
      "label": "Week 3"
    },
    {
      "id": "18dc5064ba7bb577",
      "type": "group",
      "styleAttributes": {},
      "x": -607,
      "y": 2130,
      "width": 300,
      "height": 300,
      "label": "Untitled group"
    },
    {
      "id": "8857c6d116c6f967",
      "type": "text",
      "text": "| 09.17.24 | Course Topics Discussion            | Chapter 1       |\n| -------- | ----------------------------------- | --------------- |\n| 09.19.24 | Ethics: Unworkable Ethical Theories | Secs. 2.1 - 2.5 |",
      "styleAttributes": {},
      "x": -740,
      "y": 1580,
      "width": 491,
      "height": 66
    },
    {
      "id": "5578b515503c8aca",
      "type": "text",
      "text": "### Lecture 4 09.17.24",
      "styleAttributes": {},
      "x": -754,
      "y": 1680,
      "width": 260,
      "height": 60
    },
    {
      "id": "5a0f1c1a38dce28f",
      "type": "text",
      "text": "#### Chapter 1\n[[Ethics for the Information Age, 9e.pdf#page=57&annotation=2405R|Ethics for the Information Age, 9e, page 57]]\n> The traditional view of technology, called **instrumentalism**, sees technological devices as instruments created by engineers to achieve ends dictated by society. Instrumentalists focus on the benefits of technology. They see technology as expanding human capabilities, which is desirable. While it is true that a technology may be put to a bad use, that is the fault of the human users of the technology, not the creators of the technology or the technology itself, according to this view. \n\n> The **neutrality** thesis holds that technology is neither good nor bad; it is the users of that technology who determine whether it will be put to good or bad use. A well-known example of this perspective is the statement, “Guns don’t kill people. People kill people.”\n\n> **Pragmatism** is another view of technology that focuses on the role of technological devices in solving practical problems. Unlike instrumentalists, however, pragmatists do not think technology is value neutral. Rather, in their view, the value of a technology is dependent on the social context in which it is deployed. For example, urban coal-fired steam-heating plants would have been viewed favorably in the 1880s because they were a cleaner and more efficient source of heat than the alternatives available at that time. Today, the same technology would be seen as harmful because climate change is an important social concern, and coal-fired plants emit more carbon dioxide than alternative heat sources. \n\n> **Technological determinism** is the view that technological advancements are the most important driver of social, economic, and cultural change. According to this view, technological change is autonomous and inevitable, as expressed in the familiar saying, “You can’t stop progress.” Technological determinists can point to historical events sup- porting their view. For example, the early adoption of gunpowder in Turkey enabled the creation the Ottoman Empire, and the invention of the printing press was a catalyst for the creation of nation-states in Western Europe. Modern commentators who see the rise of AI as unstoppable are reflecting a deterministic view of technology. \n\n\n> Critics of technological determinism argue that the theory is too simplistic and ignores the fact that societies do have some choice regarding whether to adopt new technologies. The **cultural approach to technology** holds that technology is an expression of human culture. Technology is value-laden because once adopted, it can impact society by making it easier for people to achieve some goals and more difficult for them to achieve others [62]. For example, as described earlier in this chapter, the adoption of the telephone facilitated long-distance communication, and the telephone also eroded traditional social hierarchies and generated new concerns about privacy. \n\n> Underlying the European colonization of the lands and people of America, Asia, and Africa was a belief system that presumed the racial inferiority of the colonized people and the inferiority of their knowledge and values. **Coloniality** refers to the situation in which these beliefs have been internalized and have persisted, even though colonialism is largely relegated to the past. Ex-colonized people believing that they are incapable of developing high quality technologies is a symptom of coloniality. Another symptom of coloniality is the view of some North Americans or Europeans that they can solve technical problems in developing nations without any help from the people who live there. Decolonial tech- nical design is the view that a pluralistic technical design process can overcome coloniality by including the knowledge, values, and world views of formerly colonized people ",
      "styleAttributes": {},
      "x": -1220,
      "y": 1817,
      "width": 1071,
      "height": 767
    },
    {
      "id": "75f917c8fd20cde3",
      "type": "text",
      "text": "*literally just going over the textbook reading*",
      "styleAttributes": {},
      "x": 1580,
      "y": 1710,
      "width": 260,
      "height": 60
    },
    {
      "id": "abd6237a4e0a3072",
      "type": "text",
      "text": "### Lecture 5 09.19.24",
      "styleAttributes": {},
      "x": 1080,
      "y": 1680,
      "width": 260,
      "height": 60
    },
    {
      "id": "12576adfdb6b2e62",
      "type": "text",
      "text": "**Workable ethical theory**: produces explanations that aim to be persuasive to a skeptical, yet open-minded audience",
      "styleAttributes": {},
      "x": 1100,
      "y": 1760,
      "width": 440,
      "height": 60
    },
    {
      "id": "882c06f901ffd9fe",
      "type": "file",
      "file": "W2024/W2024T1/CPSC 430/CPSC 430 Essay 2 Outline.md",
      "styleAttributes": {},
      "x": -80,
      "y": 1817,
      "width": 649,
      "height": 360
    },
    {
      "id": "a2bc8a68712d7fe5",
      "type": "text",
      "text": "#### Subjective Relativism \n> We are unable to understand or judge each other, so universal ethical statements are impossible\n\n\nKevin thinks that this is not \"morally open minded\"\n\nDitto for **cultural relativism**",
      "styleAttributes": {},
      "x": 1000,
      "y": 1880,
      "width": 460,
      "height": 193
    },
    {
      "id": "e82bd32dce95b53f",
      "type": "text",
      "text": "Argue **against**\n\nSocial networks should be held legally liable for the content of any post promoted to the feeds of over 100k users\n\n- Not liable for user's actions\n- Privacy concerns\n- Countries have varying laws; which defer to \n- **Person posting** should be held liable\n- Not **feasible** to screen that much content; 100k is low bar in grand scheme \n- **Censorship** from over-screening bad for user base & freedom\n- Retroactively becoming illegal either thru post editing or new laws\n- Can just cap your illegal posts at 99k \n\nSection 230",
      "styleAttributes": {},
      "x": 1640,
      "y": 280,
      "width": 451,
      "height": 432
    },
    {
      "id": "adf6a33d33fc5f64",
      "type": "text",
      "text": "### Lecture 3 09.12.24",
      "styleAttributes": {},
      "x": 2320,
      "y": 102,
      "width": 250,
      "height": 58
    },
    {
      "id": "0fac7b7b3bae2ea7",
      "type": "text",
      "text": "#### Speaking, Writing, and Argumentation",
      "styleAttributes": {},
      "x": 2400,
      "y": 192,
      "width": 420,
      "height": 60
    },
    {
      "id": "3dd93f54ee4552f4",
      "type": "file",
      "file": "W2024/W2024T1/W2024T1 Files/Lect1-2.pdf",
      "styleAttributes": {},
      "x": 2320,
      "y": 280,
      "width": 400,
      "height": 298
    },
    {
      "id": "4a13c4c9714fd8b6",
      "type": "text",
      "text": "### Due 09-10-24 5:00PM\n- [x] Readings\n- [x] MTA: \n\t- [x] Calibrate peer reviews \n\t- [x] Complete quiz\n\t- [x] Write outline (150char) for essay \n- [x] Write essay in CBTF\n\t- [x] Attempt 1: 09-09-24 12-1PM\n\t- [ ] Attempt 2: 09-10-24 3-4PM\n- [x] Join piazza\n",
      "styleAttributes": {},
      "x": -369,
      "y": 160,
      "width": 344,
      "height": 302
    },
    {
      "id": "adec35d50cea2a55",
      "type": "file",
      "file": "W2024/W2024T1/CPSC 430/Lect0.pdf",
      "styleAttributes": {},
      "x": -494,
      "y": 496,
      "width": 660,
      "height": 504
    },
    {
      "id": "2528eb2697d45091",
      "type": "text",
      "text": "#### Articles on Writing: [[All_Articles_on_Writing_A0w74ic_2_EYwx96N_WK33B2M_FIRiUnz_mXpyVsH.pdf]]",
      "styleAttributes": {},
      "x": -780,
      "y": 101,
      "width": 375,
      "height": 121
    },
    {
      "id": "844b0e21fd20e4ee",
      "type": "text",
      "text": "#### Mock debate",
      "styleAttributes": {},
      "x": 1591,
      "y": 192,
      "width": 250,
      "height": 60
    },
    {
      "id": "3da553b3f5bc3f6a",
      "type": "file",
      "file": "W2024/W2024T1/W2024T1 Files/Lect1-3.pdf",
      "subpath": "#page=1",
      "styleAttributes": {},
      "x": -1220,
      "y": 2584,
      "width": 820,
      "height": 416
    },
    {
      "id": "4e3e08900efa83cf",
      "type": "file",
      "file": "W2024/W2024T1/CPSC 430/CPSC 430 Essay 1 Outline.md",
      "styleAttributes": {},
      "x": 140,
      "y": 162,
      "width": 680,
      "height": 300
    },
    {
      "id": "d1c96d0adccc28ef",
      "type": "text",
      "text": "### Lecture 2 09.10.24",
      "styleAttributes": {},
      "x": 1527,
      "y": 102,
      "width": 250,
      "height": 58
    },
    {
      "id": "213e1c0506d3be8a",
      "type": "file",
      "file": "W2024/W2024T1/W2024T1 Files/Lect1-1.pdf",
      "styleAttributes": {},
      "x": 1191,
      "y": 280,
      "width": 400,
      "height": 320
    },
    {
      "id": "5b566a3fb6273663",
      "type": "text",
      "text": "# CPSC 430 Syllabus\nhttps://www.cs.ubc.ca/~kevinlb/teaching/cs430/\n[MTA](https://mta.students.cs.ubc.ca/)\n",
      "styleAttributes": {},
      "x": -349,
      "y": -160,
      "width": 649,
      "height": 140
    },
    {
      "id": "8e5c8cb50b7301e3",
      "type": "text",
      "text": "# [[Ethics for the Information Age, 9e.pdf|Textbook]]\n",
      "styleAttributes": {},
      "x": 344,
      "y": -160,
      "width": 336,
      "height": 70
    },
    {
      "id": "40f3f152194cddf5",
      "type": "text",
      "text": "\n| CPSC_V 430-102 - Computers and Society | Lecture | Tue Thu <br>5:00 p.m. - 6:30 p.m. MCML-Room 166 | Kevin Leyton-Brown |\n| -------------------------------------- | ------- | ----------------------------------------------- | ------------------ |\n",
      "styleAttributes": {},
      "x": -349,
      "y": -280,
      "width": 649,
      "height": 78
    },
    {
      "id": "1e15e876970da15f",
      "type": "text",
      "text": "## CPSC 430 Schedule\n\n| Date     | Topic                                              | Readings                                               |\n| -------- | -------------------------------------------------- | ------------------------------------------------------ |\n| 09.05.24 | Introduction - [[Lect0.pdf\\|Slides]]               |                                                        |\n| 09.10.24 | Course Topics Discussion - [[Lect1-1.pdf\\|Slides]] | Material on writing linked above                       |\n| 09.12.24 | Writing and Argument - [[Lect1-2.pdf\\|Slides]]     |                                                        |\n| 09.17.24 | Course Topics Discussion - [[Lect1-3.pdf\\|Slides]] | Chapter 1 [[Ethics for the Information Age, 9e.pdf\\|]] |\n| 09.19.24 | Ethics: Unworkable Ethical Theories                | Secs. 2.1 - 2.5                                        |\n| 09.24.24 | Ethics: Kantianism                                 | Secs. 2.6 - 2.8                                        |\n| 09.26.24 | Ethics: Utilitarianism                             |                                                        |\n| 10.01.24 | Ethics: Social Contract Theory                     | Secs. 2.9 - 2.12                                       |\n| 10.03.24 | Ethics: Virtue Ethics                              |                                                        |\n| 10.08.24 | Networked Communications                           | Chapter 3                                              |\n| 10.10.24 | Networked Communications                           |                                                        |\n| 10.15.24 | Intellectual Property                              | Chapter 4                                              |\n| 10.17.24 | Intellectual Property                              |                                                        |\n| 10.22.24 | Information Privacy                                | Chapter 5                                              |\n| 10.24.24 | Information Privacy                                |                                                        |\n| 10.29.24 | Privacy and the Government                         | Chapter 6                                              |\n| 10.31.24 | Privacy and the Government                         |                                                        |\n| 11.05.24 | Computer and Network Security                      | Chapter 7                                              |\n| 11.07.24 | Computer and Network Security                      |                                                        |\n| 11.12.24 | No Class: Midterm Break                            |                                                        |\n| 11.14.24 | Computer Reliability                               | Chapter 8                                              |\n| 11.19.24 | Professional Ethics                                | Chapter 9                                              |\n| 11.21.24 | Work and Wealth                                    |                                                        |\n| 11.26.24 | Work and Wealth                                    | Chapter 10                                             |\n| 11.28.24 | Artificial Intelligence                            |                                                        |\n| 12.03.24 | Artificial Intelligence                            | TBA                                                    |\n| 12.05.24 | Artificial Intelligence                            | TBA                                                    |",
      "styleAttributes": {},
      "x": -1480,
      "y": -374,
      "width": 640,
      "height": 854
    },
    {
      "id": "196c0f18998ee2a2",
      "type": "text",
      "text": "#### [[Ethics for the Information Age, 9e.pdf#page=107&annotation=2663R|Virtue Ethics]]\n\n**Aristotle:**\n>  Intellectual virtues are those virtues associated with reasoning and truth. Moral virtues, often called virtues of character by today’s writers, are habits or dispositions formed through the repetition of the relevant virtuous actions  \n\n> Morally good people consistently do what is right; it becomes second nature to them. Note, then, that a moral virtue is not simply a disposition to act in a particular way, it is also a disposition to feel in a particular way. ",
      "styleAttributes": {},
      "x": -1146,
      "y": 5449,
      "width": 660,
      "height": 260
    },
    {
      "id": "e9b11c96dc3a2d54",
      "type": "text",
      "text": "### Essay 7 ",
      "styleAttributes": {},
      "x": -753,
      "y": 6000,
      "width": 250,
      "height": 60
    },
    {
      "id": "4a85d63e19b21cda",
      "type": "text",
      "text": "2. No, because this puts customers at risk of privacy violations and introduces security risk. The majority of users will be completely unaware that these files have their personal information. If an iTunes user distributes their purchased file under Fair Use terms, they would be unknowingly sharing personal information. \nCategorical imperative; does it create a logical contradiction to say that this is moral? \n- If we generalize this rule; that it is acceptable for corporations to essentially put identifying/tracker tags on all products, this enables greater surveillance \n\n\"you should be able to track your customers' use of your product to \"",
      "styleAttributes": {},
      "x": -891,
      "y": 6466,
      "width": 491,
      "height": 394
    },
    {
      "id": "2ee057a9210bbf47",
      "type": "text",
      "text": "Overly logical; authority or ability to quantify – illogical to think this is possible & false sense of security \n\nWhat value do numbers have if they're ultimately inevitably arbitrary\n- Highway example",
      "styleAttributes": {},
      "x": 860,
      "y": 4240,
      "width": 320,
      "height": 197
    },
    {
      "id": "b5d401081f98b46b",
      "type": "file",
      "file": "W2024/W2024T1/CPSC 430/CPSC 430 Essay 4 Outline.md",
      "styleAttributes": {},
      "x": -426,
      "y": 4529,
      "width": 600,
      "height": 81
    },
    {
      "id": "a263db81a669ce09",
      "type": "text",
      "text": "#### [[Ethics for the Information Age, 9e.pdf#page=100&annotation=2634R|Social Contract Theory]]\n>  Hobbes argues that everybody living in a civilized society has implicitly agreed to two things: (1) the establishment of such a set of moral rules to govern relations among citi- zens and (2) a government capable of enforcing these rules. He calls this arrangement the social contract.\n\n> Social Contract Theory Morality consists in the set of rules, governing how people are to treat one another, that rational people will agree to accept, for their mutual benefit, on the condition that others follow those rules as well.\n\n**Rights**\n> A negative right is a right that another can guarantee by leaving you alone to exercise your right. \n> \n> A positive right is a right that obligates others to do something on your behalf. \n> \n> An absolute right is a right that is guaranteed without exception. Negative rights, such as the right to life, are usually considered absolute rights. \n> \n> A limited right is a right that may be restricted based on the circumstances.\n\n\n**John Rawls' Principles of Justice**\n> 1. Each person may claim a “fully adequate” number of basic rights and liberties, such as freedom of thought and speech, freedom of association, the right to be safe from harm, and the right to own property, so long as these claims are consistent with everyone else having a claim to the same rights and liberties. \n> 2. Any social and economic inequalities must satisfy two conditions: first, they are associated with positions in society that everyone has a fair and equal opportunity to assume; and second, they are “to be to the greatest benefit of the least-advantaged members of society (*the difference principle*)”\n\nPotential counterarguments: [[Ethics for the Information Age, 9e.pdf#page=106&annotation=2659R|The Case Against Social Contract Theory]]\n",
      "styleAttributes": {},
      "x": -1146,
      "y": 4652,
      "width": 660,
      "height": 743
    },
    {
      "id": "9eee6e2d167791bc",
      "type": "text",
      "text": "**Falsifying documents**: A nurse’s close friend is in desperate need of medical help but cannot afford treatment. Is it morally justifiable for the nurse to falsify medical documents to help their friend, even though it violates their professional duties? Evaluate this from the perspective of social contract theory and/or virtue ethics.",
      "styleAttributes": {},
      "x": -1146,
      "y": 4529,
      "width": 660,
      "height": 103
    },
    {
      "id": "88f4803ba99ebc3b",
      "type": "file",
      "file": "W2024/W2024T1/CPSC 430/CPSC 430 Essay 5 Outline.md",
      "styleAttributes": {},
      "x": 200,
      "y": 4529,
      "width": 594,
      "height": 90
    },
    {
      "id": "8a44a6c3321d3e5e",
      "type": "file",
      "file": "W2024/W2024T1/CPSC 430/CPSC 430 Essay 6 Outline.md",
      "styleAttributes": {},
      "x": 820,
      "y": 4529,
      "width": 590,
      "height": 757
    },
    {
      "id": "bb6a83402d8dfee8",
      "type": "text",
      "text": "### Quiz\n- 1. Q1:\n    \n    Who wrote an influential paper in the 1890s urging that privacy rights be enacted into law?\n    \n    - 1- Benn and Brandeis\n    - 2- Levine and Benn\n    - 3- Thomson and Warren\n    - 4- **Warren and Brandeis**\n- 2. Q2:\n    \n    Who wrote that every violation of a “privacy right” is also a violation of another right?\n    \n    - 1- Stanley Benn\n    - 2- Morton Levine\n    - 3- **Judith Jarvis Thomson**\n    - 4- Samuel Warren\n- 3. Q3:\n    \n    Most commentators cite the benefits of privacy as a reason why people ought to have some privacy rights. A right that benefits society is called a\n    \n    - 1- Constitutional right.\n    - 2- legal right.\n    - 3- natural right.\n    - 4- **prudential right.**\n- 4. Q4:\n    \n    A public record contains information about an incident or action reported to a government agency for the purpose of\n    \n    - 1- enhancing public safety.\n    - 2- **informing the public.**\n    - 3- protecting the innocent.\n    - 4- regulating the economy.\n- 5. Q5:\n    \n    An example of a public record is\n    \n    - 1- a birth certificate.\n    - 2- a marriage license.\n    - 3- a record of a criminal conviction.\n    - 4- **All of the above**\n- 6. Q6:\n    \n    What benefit does a company gain by allowing people to login to its app using Facebook Login?\n    \n    - **1- It gains access to information from the consumers’ Facebook profiles. <**\n    - 2- It is paid a royalty from Meta.\n    - 3- It suffers less credit card fraud.\n    - 4- All of the above\n- 7. Q7:\n    \n    The process of searching through many records in one or more databases looking for patterns or relationships is called\n    \n    - 1- credit reporting.\n    - **2- data mining.**\n    - 3- information gathering.\n    - 4- pattern matching.\n- 8. Q8:\n    \n    When information collected for one purpose is put to another purpose, that is called a\n    \n    - 1- backdoor exploit.\n    - 2- collaborative filter.\n    - 3- data leveraging opportunity.\n    - **4- secondary use of the data.**\n- 9. Q9:\n    \n    A policy that requires the consumer to explicitly give permission before an organization can share information with another organization is called\n    \n    - 1- fair use.\n    - 2- full disclosure.\n    - **3- opt-in.**\n    - 4- opt-out.\n- 10. Q10:\n    \n    The practice of mailing advertisements only to the most likely prospects is called\n    \n    - 1- discriminatory mailing.\n    - 2- mail list trimming..\n    - 3- predatory mailing.\n    - 4- **targeted direct mail.**",
      "styleAttributes": {},
      "x": -1502,
      "y": 6467,
      "width": 487,
      "height": 1728
    },
    {
      "id": "af64e1b312466a8e",
      "type": "file",
      "file": "W2024/W2024T1/Screenshots/Screenshot 2024-10-18 at 9.07.58 AM.png",
      "styleAttributes": {},
      "x": -1563,
      "y": 6100,
      "width": 1163,
      "height": 336
    },
    {
      "id": "b196eb62074386e5",
      "type": "text",
      "text": "It is not fair for a store to charge more to customers who do not sign up for its loyalty card, as it corners many customers into essentially selling their information in exchange for food. \n\nIf the prices are the same as other stores for members but more expensive for non-members, then people who do not want to give companies their data are put in the position to either have to travel further out of their way to avoid paying more for groceries. People who are unable to do so, and who are unable to pay even higher costs for groceries, are thus cornered into getting a loyalty card and giving the company their information. Even if the member prices are cheaper than other stores, the price of food is so high that opting for discounts is less of a way of saving money and more of a necessity to buy food at all. \n\nThis policy is a violation of the first and second formulations of the categorical imperative. Universalizing this rule, all stores can offer member discounts in exchange for customer information. This creates a society where the expectation of selling your data to a company is so ubiquitous that privacy ceases to exist altogether, as any company you have purchased a product from has access to your \"personal\" information. This is a logical contradiction. By the second formulation, companies are using customers as a means to an end. Rather than aiming to provide goods and services at a reasonable price, companies now aim to collect customer data for purposes of targeted advertising and data mining. Both of these infringe on customer's privacy for the aims of increasing company profit. \n\nA counterargument is that people are knowingly giving up personal information, and it may feel insignificant to do so given how much is available publically online. If consent is given, then it is not immoral for companies to use information which they have been given access to. However, this assumes that people are aware of the full extent to which their information can be used. Purchases, as shown by Target's maternity-tracking, can give an incredibly detailed profile of someone's life. Tyeing purchases to a face and name gives a more detailed profile than scrubbing a social media account, and one which many people would not be comfortable with companies having, much less selling for secondary purposes. Because it is immoral to engage in transactions under false or misleading pretense, member discounts are not moral.",
      "styleAttributes": {},
      "x": -283,
      "y": 6100,
      "width": 543,
      "height": 880
    },
    {
      "id": "09bc4176dfc81f64",
      "type": "text",
      "text": "Loyalty cards are immoral under Kantianism for two reasons: exploits a need, food, and is an imbalanced transaction, as one party (the store) knows more about the consequence of the transaction than the consumer. \n\nPrice gouging groceries for non-members is immoral under both formulations of the Categorical Imperative (CI). Firstly, universalizing price gouging for products creates a world in which price no longer has any relationship to value of a good. Because circumstances (ie. food deserts) exist where there is not sufficient market pressure to lower grocery prices, and stores have near-total control of essential grocery costs, customers suffer ",
      "styleAttributes": {},
      "x": -283,
      "y": 7020,
      "width": 543,
      "height": 380
    },
    {
      "id": "ce9e2fbe9768b40c",
      "type": "text",
      "text": "rolling out self driving cars to reduce traffic accidents is a less tenable and more environmentally destructive solution than improving public transportation",
      "styleAttributes": {},
      "x": -1220,
      "y": 3040,
      "width": 443,
      "height": 76
    },
    {
      "id": "c5d406d914208f3c",
      "type": "text",
      "text": "Sensitive information tracking does not justify umbrella surveillance\n\nsurveillance rarely improves workplace conditions\n\nfurthering power disparity between employer/employee\n\nif this data is automatically reviewed (likely esp in big companies since it would be sm info): overly punitive towards diff work styles such as working things out on paper ",
      "styleAttributes": {},
      "x": -1220,
      "y": 3144,
      "width": 443,
      "height": 241
    },
    {
      "id": "c4b195bdf8dc1012",
      "type": "text",
      "text": "### 09.26.24",
      "styleAttributes": {},
      "x": 920,
      "y": 3620,
      "width": 260,
      "height": 60
    },
    {
      "id": "84e4889dd41eecfa",
      "type": "text",
      "text": "Philosophies which could be described as utilitarian\n- Ethical egoism\n- Social contract theory",
      "styleAttributes": {},
      "x": 940,
      "y": 3720,
      "width": 300,
      "height": 128
    },
    {
      "id": "d40c7483ff407d5e",
      "type": "text",
      "text": "Principle of Utility - \"Greatest Happiness Principle\"",
      "styleAttributes": {},
      "x": 540,
      "y": 3695,
      "width": 380,
      "height": 50
    },
    {
      "id": "2ac44bbcc1c552ef",
      "type": "text",
      "text": "### 09.24.24: Kant",
      "styleAttributes": {},
      "x": -340,
      "y": 3760,
      "width": 260,
      "height": 60
    },
    {
      "id": "4629149cbe263acb",
      "type": "text",
      "text": "1. Quantify utility \n2. Sum harms vs benefits\n3. Whichever way the scale tips",
      "styleAttributes": {},
      "x": 940,
      "y": 3880,
      "width": 300,
      "height": 100
    },
    {
      "id": "f4bdd6b84593ce1c",
      "type": "text",
      "text": "Rule vs Act Utilitarianism ",
      "styleAttributes": {},
      "x": 660,
      "y": 3980,
      "width": 260,
      "height": 60
    },
    {
      "id": "adc561ea4ee6bdfa",
      "type": "text",
      "text": "me",
      "styleAttributes": {},
      "x": 856,
      "y": 4127,
      "width": 260,
      "height": 60
    },
    {
      "id": "239d2c25443b0136",
      "type": "text",
      "text": "Against act utilitarianism: \n\n- problem of scope: what is in calculation?\n- ignores innate sense of duty\n- s",
      "styleAttributes": {},
      "x": 1249,
      "y": 4038,
      "width": 260,
      "height": 182
    },
    {
      "id": "e2e30c276f928d07",
      "type": "text",
      "text": "### Essay 3 \nCan moral decisions be made on a purely rational, algorithmic basis, or are there limits to rationality in moral decision making? ",
      "styleAttributes": {},
      "x": -1140,
      "y": 3580,
      "width": 460,
      "height": 128
    },
    {
      "id": "5e69ebb0d0967f27",
      "type": "file",
      "file": "W2024/W2024T1/CPSC 430/CPSC 430 Essay 3 Outline.md",
      "styleAttributes": {},
      "x": -580,
      "y": 3644,
      "width": 693,
      "height": 39
    },
    {
      "id": "a06ef4e732c993ef",
      "type": "text",
      "text": "**Purely** rational, algorithmic\n1. Moral decisions often have a significant emotional/relational/social component which can't be easily quantified into a moral equation\n2. Bias; who decides the steps of the algorithm? Who provides the contextualizing information from which the decision is made? ; \"moral experts?\"\n3. Counter:\n\tIt is possible to break situations down to their essential components and to analyze them from their in a democratized process so as to remove individual biases and provide an expansive perspective. \n\tRebuttal:\n\tThis is maybe as close as we can get (barring a hypothetical perfect moral AI), but \"purely\" demands a level of definitiveness that is just not possible outside of theory. We will always be limited by what we know",
      "styleAttributes": {},
      "x": -910,
      "y": 3740,
      "width": 460,
      "height": 389
    }
  ],
  "edges": [
    {
      "id": "b22a3272f37f46cc",
      "fromNode": "4a13c4c9714fd8b6",
      "fromSide": "right",
      "toNode": "4e3e08900efa83cf",
      "toSide": "left"
    },
    {
      "id": "b4db3a44ce675394",
      "styleAttributes": {},
      "fromNode": "adc561ea4ee6bdfa",
      "fromSide": "bottom",
      "toNode": "2ee057a9210bbf47",
      "toSide": "top"
    }
  ],
  "metadata": {}
}