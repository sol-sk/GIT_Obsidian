[[syllabus_365_2024W-1.pdf]]

| PSYC_V 365-002 - Cognitive Neuroscience | Lecture | Tue Thu <br>3:30 p.m. - 5:00 p.m. <br>MATH-Room 100 | Brandon Forys | 2   |
| --------------------------------------- | ------- | --------------------------------------------------- | ------------- | --- |
### Readings and Assessments

| 1   | 01.07.25 | Introduction/Syllabus Module Syllabus                                                                                               |
| --- | -------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| 2   | 01.09.25 | Cognitive Neuroscience: The Good, the Bad, and the Ugly Passingham Chap 1; How to Read a Scientific Paper for Non-Scientists        |
| 3   | 01.14.25 | Quiz: Cognitive Neuroscience methods Neuroanatomy module; Poldrack & Farah, 2015                                                    |
| 4   | 01.16.25 | fMRI: Workhorse of Cog Neuro Dimsdale-Zucker et al., 2018, section 1 only                                                           |
| 5   | 01.21.25 | Recognizing objects Part 1 Passingham Chap. 2 to pg. 58 (Classifying Objects); Brain facts: How AI helps us understand human vision |
| 6   | 01.23.25 | Recognizing Objects Part 2 Neural networks made easy; Bowers et al., 2023 (pgs. 1-19)                                               |
| 7   | 01.28.25 | What is special about faces? Harada et al., 2020; Cracking face code                                                                |
| 8   | 01.30.25 | Review                                                                                                                              |
| 9   | 02.04.25 | **Midterm 1**                                                                                                                       |
| 10  | 02.06.25 | Guest lecture (to be announced) TBD                                                                                                 |
| 11  | 02.11.25 | Classifying objects Passingham Chap. 2 pg. 58 (Classifying Objects)                                                                 |
| 12  | 02.13.25 | Predicting Perception Egner, Monti, and Summerfield, 2009 17-21 Feb NO CLASS – Reading Week                                         |
| 13  | 02.25.25 | Selecting attention Passingham Chap. 3; Videos                                                                                      |
| 14  | 02.27.25 | Sustaining attention Rosenberg et al., 2016                                                                                         |
| 15  | 03.04.25 | Emotion, motivation and attention Inman et al., 2023                                                                                |
| 16  | 03.06.25 | Review                                                                                                                              |
| 17  | 03.11.25 | **Midterm 2**                                                                                                                       |
| 18  | 03.13.25 | Reward and attention (& learning) Anderson et al., 2016; 2 Dopamine blogs                                                           |
| 19  | 03.18.25 | The Hippocampus: From space travel to time travel Passingham Chapter 4; Fernandez- Velasco & Spiers, 2024                           |
| 20  | 03.20.25 | Episodic memory How to See a Memory                                                                                                 |
| 21  | 03.25.25 | Rehearsing and retrieving memories Bird et al., 2015                                                                                |
| 22  | 03.27.25 | **Midterm 3**                                                                                                                       |
| 23  | 04.01.25 | Final projects                                                                                                                      |
| 24  | 04.03.25 | Final projects                                                                                                                      |
| 25  | 04.08.25 | Final projects                                                                                                                      |




# 01.07.25 Lecture 1
[[Class1_365_2025.pdf]]
Understanding relationship between brain activity and cognitive processes

# 01.09.25 Lecture 2
[[Class2_365_2025.pdf]]
[[Raff How to read and understand a scientific paper a guide for non-scientists|Raff how to read]]
[[Cognitive Neuroscience_ A Very Short Introduction-Passingham.pdf|Passingham Ch2]]
[[Class3_365_2025.pdf]]

# 01.30.25 Lecture 8

**SHORT ANSWER QUESTION**  
Answer the following based on the paper we read by Harada et al., 2020, which used fMRI to examine  
questions related to face perception and race/culture, as well what you know from lecture material  
about the paper (30 points).  

- **A. What was the big-picture question that motivated the study? (1 pt total)**  

- **B. Background (6 pts total)**  
	- *I. Describe one thing that previous research, described in the Introduction of the paper, has taught us about the influence of culture on responses to facial emotion and one set of findings described in the paper that support that knowledge. Your answer for the  second part of this question (about the set of findings) should elaborate on your answer  in the first part of this question. (4 pts)* 
	- Previous studies have shown in-group affects on bilateral amygdala response. 
	- *II. What two self-construal styles have been identified by cultural psychologists and what are the main characteristics of each? (2 pts)*  
- **C. Research Questions and Hypotheses (3 pts total)**  
	- *I. What was the main research question? (1 pt)*  
	- How do Japanese bicultural individuals (raised in individualistic culture but with connections to collectivistic) compare to Native Japanese (collectivism) in amygdala response to racial in and out group faces? ("That is to say, what neural modulation in the amygdala would be observed in Japanese-American individuals, who are very familiar with Caucasian-Americans’ faces while they have a similarity of physical appearance to native Japanese people, when they were shown facial emotional ex- pressions of Caucasians and Japanese?")
	- *II. What were two hypotheses put forward by the authors? (2 pts)*  
	-  Bicultural (Japanese American) individuals would show greater amygdala response to Japanese faces than Caucasian Americans, and "collectivistic tendencies would be related to neural responses of intergroup negative facial expression."
- **D. Methods (2 pts total)**  
	- *I. How did they define group membership? (1 pt)*  
	- Japanese-Americans were born and/or raised from a young age in America, either first-generation or second-generation. Japanese Natives were born and raised in Japan, and Caucasian Americans. In-group for Japanese Americans was racial in group ie. Japanese. 
	- *II. What was the purpose of the shape stimuli? (1 pt)*  
	- The shape stimuli serve as a control task for a "relatively low-level cognitive process"  
- **E. Results (4 pts total)**  
	- *I. What was the main pattern of findings for the amygdala? What patterns of brain  activity reflected the “cultural in-group effect?” (2 pts)*  
	- There was a significant in-group effect observed in the bilateral amygdala when comparing Native Japanese group with Caucasian-American group. Native Japanese participants showed larger neural responses itn the bilateral amygdala to Japanese faces than Caucasian-Americans did. 
	- Caucasian-American and Japanese participants showed the highest amygdala activities to negative faces of the same cultural and racial members (i.e. in-group members) and the lowest amygdala activities to those of the different cultural and racial group members
	- Japanese-American participants showed neural responses in between the JN and CA groups. 
	- *II. What pattern of brain activity did they find in one particular group of participants when  they looked at the whole brain? (2 pts)*  
	-  Japanese-American participants showed greater activities in the right ventral prefrontal cortex, posterior cingulate cortex extending to precueus and right superior frontal gyrus during processing of negative facial expressions of Japanese than Caucasian-American participants did
- **F. Discussion (4 pts total)**  
	- *I. How do they interpret the midline cortical findings observed in one particular group? (2  pts)*  
	- Likely reflects greater informational demands of self-relevant memory, because their recognition of their racial identity might be automatically strengthened when negative facial expression of racially in-group members was presented.
	- *II. Was their hypothesis about individual differences supported? Why or why not? (2 pts)*  
	- "This result indicates that bicultural individuals respond to negative facial expressions of members from the both cultural groups with slightly attenuated extent as compared to monocultural individuals. We hypothesized that JA individuals would show large amygdala responses to Caucasian negative faces as the same extent as CA individuals would if the in-group bias was due to familiarity of faces learned in their daily life, while they would show large amygdala response to Japanese negative faces as the same extent as JP individuals would if the in-group bias was simply due to their racial identity. The results in the current study did not support either hypothesis"
	- "Although this way might not necessarily eliminate the possibility of remaining variations, it would be still a possible solution and even more useful way by combining with an additional and detailed reliability test such as a ROI analysis for target brain regions that we have done in the current study. In the current study, we excluded the temporal and occipital regions from the analyses only when directly comparing the different facilities, and furthermore confirmed that there was no significant difference of neural activities in the hypothesized regions, that is the bilateral amygdala, in our prior reliability test. Hence, variation in scanner-site performance is not a likely explanation for the variability in the neural activation we observed in the current study."
- **G. Conclusions and limitations (6 pts total)**  
	- *I. How do they describe the overall meaning and importance of the results? (2 pts)*  
	- "Our results show that neural responses in the bilateral amygdala reflected both of in-group biases based on ones’ racial identities and cultural practices, such as ones’ collectivistic tendencies, irrespective of participants’ cultures."
	- "Our results demonstrate that neural responses during the processing of emotional faces could be modulated by different social factors, such as cultural practice and racial identity, and furthermore cultural and racial influences are interlaced especially in bicultural individuals such as Japanese-Americans in the current study."
	- *II. List TWO limitations of the study and explain why they are limitations. (4 pts)*  
	- One limitation of this study involves the generalizability of our findings, as the results were based on only facial expressions of fear and anger.
	- There might be another limitation in the current study, that is a possible variation in the scanner performance between the two facilities which may have led to variations in the neural activation patterns across the two different scanning sites.
- **H. In YOUR opinion (4 pts total)**  
	- *I. What are the larger cultural or societal implications of these findings? Do you agree  with the authors’ conclusions? Why or why not? What do you think is important that  they didn’t think of? (4 pts)*

# Midterm 2

## Class 10 - Guest Lecture

[[psyc365_guestlecture_Class10_.pdf]]

> [!note] Suggestion –
> Focus on the descriptions of the tasks used and the key takeaways given for each study. Questions about this guest lecture would appear in the multiple choice section only.

### Study – Reward sensitivity, facial emotion recognition, self-referential processing in MDD & BSD
- **Aim**: Reward sensitivity, facial emotion judgement, self-referential processing in acutely depressed people with MDD + BSD vs healthy control
- **Hypotheses**: 
	- Reward sensitivity: MDD < BSD < CTL 
	- Facial emotion recognition: MDD > BSD 
	- Self-referential processing: MDD = BSD > CTL
##### Monetary incentive delay task
Earning tickets towards draw for $100 prize when they reacted quickly enough (pressing space bar to smily face)
Asked how excited they were about how many tickets they were playing for (# varied)

##### Facial emotion labeling task
Morphed facial continuum from sad to happy 
Shift point: where on continuum participant shifted from identifying face as happy/sad
Slope: rate at which response shifted from happy to sad 

##### Self-referential encoding and memory task
Presented with words describing personal characteristics/trait
Positive/negative self-referential encoding - how many pos/neg words participants chose as describing self

Memory bias: asked after a time what words they could rememeber from the list, measuring if they remembered more neg or pos words

#### Results & Key takeaways
**Results:**
- Individuals with MDD had sig. lower anticipatory reward sensitivity than BSD participants (p = .006, d = .73) and control participants (p < .001, d = 1.14)  Participants with BSD did not differ from controls in anticipatory reward sensitivity (p = .454)
	- Reward sensitivity: MDD < BSD = CTL

- MDD/BSD/CTL (control) groups did not have significant differences in labelling faces as sad vs. happy or sensitivity to the changes in expressed emotions
	- Facial emotion: MDD = BSD = CTL 

- Individuals with MDD endorsed sig. fewer positive traits than the BSD (p = .002, d = .80) and CTL groups (p < .001, d = 2.01) 
- Individuals with BSD endorsed sig. fewer positive traits compared to CTLs (p <.001, d = 1.11) 
- MDD and BSD did not differ sig. for number of negative traits (p = .535) or negative self-referential memory bias (p = .311)
	- Pos traits: MDD < BSD < CTL
	- Neg traits: no significant results 

**Conclusions:**
*Ppl w BSD have more anticipatory reward sensitivity & positive self-referential encoding* 
*→ May help with ddx-- identifying MDD vs BSD*

### Study – Cognitive-Affective processes heterogeneity in MDD & BSD
- Background: Diff.s in cogn-affective processes exist among currently-depressed ppl w/ MDD vs BSD
	- As a group, BSD ascribe more pos traits compared to MDD/CTLs, & have greater anticipatory reward sensitivity 
- **Research question**: How much heterogeneity is there among BSD? – better, more personalized treatment
	- Why might there be heterogeneity? 
		- Depressive episodes can look diff 
		- Prev research has explored that clusters of cogn. affective processing across mood spectrum include participants who are not acutely depressed – these studies looked primarily at facial recognition tasks 
- **Aim**: To identify *data-driven subgroups* based on cogn-affective processing amongst acutely depressed indiv w/ MDD & BSD

##### Monetary Incentive Delay Task
##### Self-referential Encoding and Memory task

##### Analyses
1. Identify clusters/sub-groups
2. Assess cluster diff in task performance & clinical/demographic var. 
3. Assess proportion of diagnoses across clusters

#### Results
![[psyc365_guestlecture_Class10_.pdf#page=22|Class10_psyc365_guestlecture, page 22]]
**Cluster 1: "Negative-Low-Rewarders"**
- Significantly lower anticipatory reward sensitivity & positive self referential encoding, & higher negative memory bias & negative self ref
**Cluster 2: "Positive-High-Rewarders"**

Both clusters scored equiv. on depression matrix

**BSD vs MDD**
More MDD participants were NLRs 
No sign. diff in BSD participants who were NLR/PHR

More controls were PHRs

#### Key takeaways
- NLR & PHR represent distinct cogn-affective processing subgroups 
- There is heterogeneity in cogn-affective processes across mood spectrum 
- Some patients (MDD, BSD) cluster together w/ most healthy controls

*→ Personalized treatment is important*
### Study – Attentional biases in Persistent Post-Concussion Symptoms (PPCS)
Psychosocial factors greater contributors to developing PPCS than injury characteristics
Overlap with chronic pain research
- **Aims**: 
	- To describe correlations between attentional biases as measured on the attentional blink task (in terms of difficulty disengaging from pain-related stimuli), and fear-avoidance model constructs. 
	- To describe correlations between attentional biases as measured on the gaze-time task (in terms of preferential looking towards symptom- relevant stimuli), and fear-avoidance model constructs.
- **Hypotheses**: 
	- Participants who demonstrate greater attentional biases in difficulty disengaging attention from pain-related stimuli will also report greater severity of the fear-avoidance model contructs 
	- Participants who spend more time fixating attention on symptom- relevant stimuli will also report greater severity of the fear-avoidance model constructs (i.e., symptom severity, pain-catastrophizing, and fear- avoidance behaviour)

*Popular ways of measuring attntl biases: emotional stroop, dot probe*, but - poor split test reliability, test-retest, internal consistency, also, had to use tasks that didn't rely on reaction time, since this can also be affected post-concussion

**Groups**: 
- PPCS 
- Recovered
	- Both w/in 1 month of concussion 
##### Attentional blink task
**Standard**
- RSVP stream = rapid serial visual presentation stream
- Target 1 (T1): Letter in white that participant needs to ID
- T2: Number that participant needs to ID
- Distractors: Letters between
- Lag: Distance between targets
![[Screenshot 2025-02-27 at 1.17.42 PM.png|300]]
- Healthy participants (black line) show "attnl blink": If T2 is presented 200-400 ms after T1, we have greater difficulty IDing – theory, limitation in brains resources to ID target after just IDing
- *Hypothesis*: PPCS blue line
**Study**
Pictures instead of words for eco validity
T1: pain or neutral face
T2: bird,flower,furniture
Distractors: scrambled/pixels

##### Gaze/eye tracking task
Simulates eye-tracking w/ mouse movement
Side by side images with overlay
a) Neutral, General threat, concussion threat - b) Neutral 
general threat = natural disaster, fire, concussion threat = someone getting hit in head, MRI

#### Results - not sig. 
No diff in attnl blink for neutral or pain face
As expected: saw attnl blink for PPCS + recovered for pain faces, but did not see any diff btwn groups 
Sensitivity analysis: regrouped by fear avoidance rather than PPCS/recovered, still no sig. results

**Why not?**
- Task not sensitive enough
- Concussion images not threatening 
- Participants too removed from injury 
- Pain faces insufficiently relevant
- More complex processes

*Barriers to the implementation of new cogn paradigms into clinical practice*
- psychometric prop. 
- determining relative util
- disciriminant and predictive val
- cooperation across fields

## Class 11 - Classifying Obj and predicting perception

> [!example] Today:
> - Passingham Ch. 2
> - Selecting attn. 
> - Stim similarity in LOC
> - Reading: Egner, Monti, Summerfield 2010 [[Egner et al. - 2010 - Expectation and Surprise Determine Neural Population Responses in the Ventral Visual Stream.pdf]]

[[Class11_365_2025_notes.pdf]]
> [!Important] Content to review (from quizzes)
> - Contents of Connolly et al
> - "Which type of category would be more likely to be represented in patterns of more or less activation across voxels (multivariate patterns) than by preferential activation of whole regions in the ventral visual stream?" -- Animal classes


***Review***
- Preference in LOC for whole obj 
- Adaptive suppression in LOC for diff angles of obj

*Discussion*
- *Difference between recogn an obj and making sense of it?*
- *How is classifying an obj a form of making sense of it?*

### Inferotemporal cortex/Ventral visual system (IT)
- Important for obj categorization – *semantic* meaning of obj

Ventral visual sys (IT) categorizes obj at diff lvls:
- Superordinate, basic, subordinate, exemplar
	- Obama ex.: animate/face/man/president

#### Encoding approaches: divisions and hierarchies
Superordinate → exemplar: largest → smallest brain area (>1cm → < mm)

> It is not enough simply to recognize what we see; we also have to make sense of it. This involves classifying things, whether animate or inanimate... 
> *Passingham, Ch. 2*



##### Connolly et al: Categorizing bugs, birds & mammals 
- How are finer grained distinctions rep? 
- Prev research: funcitonal landmarks (*Animate/inanimate distinctions in IT- Grill-Spector*: Diff areas light up)
- Less known about finer distinctions
	- Diff classes of animal
- **Goal**: look at pattterns across voxels (**RSA**) to look for *similarity structures* at the level of biological class

*RSA review*
- Comparing patterns of representation, shared representational space

**fMRI experimental design**
- *Simple recognition memory task
- *Rate stimulus simularity*

"12 young adults participated in an fMRI study. As they lay there in the scanner in each trial they’d see 6 different series of 3 pictures of animals of the same class of animal -- either bugs or birds or primates. Then they would be shown one of those 6 series of 3 stimuli and would have to say if it was the same or different from what they saw in the previous trial. This probe question was just to keep the participants paying attention -- the experimenters didn't really care about how well they remembered the items. Here are some examples of the stimuli which were either bugs, birds & primates. *1) Afterwards they had participants rate how similar all of the different stimuli were to each other* and also do a task where they’d *2) see three and choose the one that wasn’t categorically like the others*. In this case they did care about the participants' choices because they wanted to know how similar or different they thought the different stimuli were from each other."

**RSA Results: LOC & IT**
- Pattern of activity represents stimuli matching behavioral similarity ratings &  mirroring biological class structure

***→ Human neuroimaging reveals a "hierarchical category structure that mirrors biological class strucutre" in ventral visual stream***

###### Using encoding for brain mapping in LOC
- How does abstr rep of continuum from bug to primate literally map to brain space 
- Does map for primates vs bugs look like animate vs inanimate? 
- Lateral-medial org. 

![[Screenshot 2025-02-27 at 1.53.36 PM.png|300]]

***→ Primate vs bug very similar to animate vs inanimate*** 

**Brain maps categories from inanimate to animate**
- Animal categories rep. medial (inanimate) → lateral (animate)
	- Only one dimension of rep obj
- Using behav judgements as target, semantic structure–ways of categorizing animals–reflected strongly thruout LOC: how much "like us" an animal is maps on to medial-lateral
	- Formed early in development, kept into late dementia

#### What we have learned from fMRI

- *Encoding Approach*: Responses to object parts and then whole objects along moving along occipital cortex from EV to LOC 
- *Encoding Approach*: More invariant processing and more category specificity as we move along ventral stream. 
- *Decoding approach*: shows continuum of finer-grained categories. 
	- In the ventral stream it matches semantic judgments of animal class 
	- In LOC it is organized along a spectrum of inanimate (not like me!) to very animate (a lot like me!)
### Predictive Coding
*Intro: waking up from anaesthetic TEDx*
- Consciousness, animal consciousness, computer consciousness
- World vs self consciousness 
- Top-down/bottom-up processing
	- Predictive hallucinations

**The problems of perception**:
- Diff objects can produce same images (e.g. orange vs orange ball)
- Same obj can produce diff images (e.g. diff angles)

*Review: Feedforward Feature Based Models*
- = Bottom-up 

→ How do we decide what to interpret an ambiguous image as? Between hypotheses H1/H2, which both equally acccount for lower-lvl features? = **Top down info**

*von Helmhotz*: First to describe brain as "prediction machine"
Perception as unconscious inference
- Cause of sensation inferred via its effects

##### Step by step of predictive coding model

![[Screenshot 2025-02-27 at 2.52.33 PM.png]]
 
*Prediction error*
- At each lvl there are "representational units" that encode expectation: probability of given stim under circumstance/conditional probability
- Send predictions to lower level for what they expect to receive
- "Error units" encode surprise: mismatch between prediction & bottom up info 
- Send mismatch info/prediction error upwards to revise hypothesis until prediction error is minimized

*Reading question:* How do predictive coding  models view the role of visual cortex neurons? 
 - Predictions based on the probability the stimulus will have particular features 
 - Error detection — they respond to a mismatch between predicted signal and actual signa
[[Class11_365_2025_notes.pdf#page=47&selection=4,0,4,16|End here]]





## Class 12 - Predictive perception, Egner et al
[[Class12_365_2025_notes-2.pdf]]

> [!example] Today:
> Reading: [[Egner et al. - 2010 - Expectation and Surprise Determine Neural Population Responses in the Ventral Visual Stream.pdf]]

[Recording](https://ubc.ca.panopto.com/Panopto/Pages/Viewer.aspx?id=bebc1490-63d8-465f-af5b-b25f0138c91a)

### Egner et al - 2010: Predictive Coding & Surprise
**Big picture question:** Do predictive coding models explain visual object recognition better than classic hierarchical feature-based models? 
	→ Examine by taking advantage of what we know about category selective voxels in fusiform face area (FFA) and parahippocampal place area (PPA)

**Predictive coding:**
- Perception is *inference*
- 2 processing units at every level of vis hierarchy
	- Representation (expectation)
	- Error (mismatch between expectation and raw evidence/surprise)
	- *Units:* populations of neurons, aka voxels in fMRI 

**Feature detection:**
- Visual neurons respond to *features* of an object
	- eg. FFA neurons respond to eyes, facial configuration, etc. 

**Research Question:** Does BOLD activity in the FFA reflect responses to expectation + surprise? Or just face features? 
**General Hypothesis:** FFA activity will be an “additive function” of expectation and surprise. 
**Alternative hypothesis:** There will always be more FFA activation to faces 
- Expectation and surprise will not matter!

- Who were the participants?: Young-ish college students w good vision
- How many of them were there?: 16? 

**Independent var:** 
- Target/non-target
- Stimulus probability (% of time face vs house)
- Stimulus feature (face/house)
**Dependent var:** 
- Reaction time
- BOLD response in FFA and PPA

**Predicted results:** 
![[Screenshot 2025-03-03 at 11.44.24 AM.png|300]]
- FFA will still activate for expectation of seeing face, not only actually seeing face 
- Additive result = face expectation + face surprise = predictive coding

**Specific hypotheses:**
- *Predictive coding:* FFA responses to faces and houses should be most different when face expectation is low
- *Feature detection:* FFA responses to faces should always be greater than hosues regardless of the level of expectation

#### Results
**Reading question**
What were the behavral (reaction time) results
Main effect: faster to ID upside down faces than houses
Did not vary by expectation condition and there was no interaciton between stim type and expectation condition 

→ if participants were paying more attn to face features in the high face expt cond then their RTs should be faster. Since they aren't, the expectation manip is probably not infl attn: Accuracy was at ceiling -- easy task 

![[Screenshot 2025-03-03 at 11.54.45 AM.png|450]]

Greatest difference in the low expectation condition 
→ high expectation: virtually identical activation between face and house

**Strongest piece of evidence:** 
PC effect was not high for houses, but when chance of seeeing face was high and house was shown, there was signf FFA actvn

Best fit PC model: 2:1 surprise/expectation effect on actvn 

*Addtl models tested:*
- Baseline shift model, addtve
- Contrast gain model, multpv

Why did they also analyze parahipp place area as test of whether FFA results generalized? → control, *to see if generalizes to other brain areas– is FFA unique in its PC?* No, it does generalize to parahipp place area

**Critiques?**
Key – we know more about relative contributions of prediction and error units. Other things in discussion – there might be an interaction with attention if that was relevant to the task. And we don’t know how much the BOLD response reflects top down vs. bottom up inputs.

Problem with computational modeling – number of parameters, parsimony, not overfitting

**Conclusions:**
- Pattern of results in FFA was consistent w response that added expectation and surprise and with predictions of computational models based on predictive coding assumptions
- They conclude → *Prediction coding models describe the process of visual inference better than feature detection* 
- Encoding predicition and error is a general characteristic of how the brain works

Minimizing prediction error; 
- Bottom up signal sends forward prediction error only– not actual signal, but when mismatch occurs 
	- Features match expectations propogate upward– ? **what did he mean by this...
- Top down signal is representation/model of the world, generating predictions at all levels of visl hierarchy– "explain away"

### Attention
Many different forms of attention
We are focusing on **selective attention** and **sustained attention**

**Monkey business illusion**
- Too many people know about the gorilla trick–focus on the gorilla, miss that the curtain also changed color, a player left the team!

##### Overview

**Selective attention**
1. Identifying targets
2. Classic model: Top down and bottom up
	1. Attl sets in top down attn
3. Dorsal (top down) and ventral (bottom up) attn networks

**Sustained attn**

Top down and bottom up are not the same in attn as obeject recognition
dorsal ventral not same as vis streams
##### Overt versus Covert attention
**Overt:** with the eyes (looking at object of attention)
**Covert:** with the mind (obj of attn is in peripheral: attend but not looking directly)
[[Class12_365_2025_notes-2.pdf#page=33&selection=2,0,2,40|Class12_365_2025_notes-2, page 33]]
1:05

#### Selective attention
** Review passingham: referenced thruout lecture

- When you filter the world so that you attend to what’s important and ignore what isn’t ie cracks in sidewalk vs whole road
- But what determines what’s important?
	- Relevance to goals 
	- “Grabbiness” (Boston Pizza, shiny things)
	- Other kinds of relevance?

##### 2 attention systems: Top down/Bottom up
***Top Down (controlled)*** 
- Deliberate 
- Conscious 
- Goal-directed (task-based) 
- *Attentional sets* 
	- Mental templates that allow us to selectively attend to a certain category of stimulus before it appears (color, shape, size) 
	- Involve holding in mind features or location of the object you’re expecting

***Bottom Up (automatic)*** 
- Involuntary 
- Captures attention 
- Despite our goals 
- Feature-based
- Can miss gradual changes 

##### Dorsal (DAN) and Ventral (VAN) Attentional Networks
![[Screenshot 2025-03-04 at 1.32.02 PM.png|450]]
- FEF= Frontal eye fields: often attune perception to area of world
 - IPS = Intraparietal Sulcus: interaction between interpretive parts of brain such as exec function
 - VFC = Ventral frontal cortex approach PFC; decision making, setting up attnl sets
 - TPJ = temporoparietal junction: similar to intraparietal sulcus 
 - V = Visual cortex

*Biased competition*: A neural mechanism for selective attention
- ie attending to stripes looking for waldo, finding some other stripy thing, bringing attention back away from it to keep searching 

Frontal and Parietal regions *modulate* activity in visual cortex

##### Interim summary 
- Selective attention is the form of attention that allows us to select what is relevant and ignore what isn’t.
- In classic models, attention can be feature-based (bottom-up), or task-based (top down) 
- These types of attention are (mostly) mediated by VAN and DAN

Simpson clip of homer getting distracted from important point

#### Sustained attention 
*What is sustained attention?* 
-  Staying on task, even when boring 
-  Often measured by the Sustained Attention to Response Task (SART) 
-  Individual differences associated with ADHD, impulsivity

*Difficulties in sustained attention*  
- Easily distracted by non-relevant stimuli  
- Often forgetful in daily activities  
- Difficulty sustaining attention during activities  
- Difficulty following instructions/failing to complete tasks  
- Missing details/making mistakes 
- Avoidance of activities that require sustained mental effort


## Class 13 - Rosenberg, Class discussion
[[Class13_365_2025_notes-1.pdf]]
[[Rosenberg_etal_2016.pdf]]
[[Tips for reading Rosenberg et al., 2016.pdf]]

> [!info] **Learning Objective**  
> - Confidently describe recent research defining a neural marker of *sustained attention* and its relationship to ADHD
> 

##### **Goal** 
Identify a neuromarker of sustained attention based on whole brain *intrinsic connectivity*
- Strength of using resting state data? -- straight-forward to collect and share across locations, cultural, language barriers; generalizable; works for participants like young children who aren't good with sustained attn task

##### **3 assumptions**
1. Individ diff in sustained attn will be reflected in complex patterns of correlated bold activity across brain reg
2. These patterns will be obsvd both when doing task and at rest
3. If we can distill a signature of these patterns we should be able to use them to predict attn ability in a completely diff set of ppl

Methods still being used today, incl. beyond sustained attn, very widely cited paper
*→ using brain connectivity measures as neuromarkers of clinical conditions*

##### **Questions to be answered:**
-  Big picture question 
	-  Can we find a neuromarker, or brain-based measure of general attentional ability? 
-  More specifically…
	-  ISO reliable marker of *overall attentional ability* observable in *resting* brains and *generalizable* to new populations 
-  **Specific question** 
	-  Can we get take a *data-driven* approach to pulling out patterns of network activity to give us a marker of sustained attention that will generalize across populations?

*What do they mean by a data-driven approach?*
- Data driven is an *exploratory* method. Instead of going in with very clear hypotheses (e.g., I think THESE regions will predict attention ability and ADHD symptoms) you measure brain activity when people are paying attention and see what the data tells YOU!. And of course they chose to measure sustained attention because it’s linked to ADHD.

Sustained attn task; fading between cities and mountains; hold button down when mountain; 90% of time city (require closer attn); higher error rate w lower sustained attn

##### Methods
-  Yale participants: 25 students 
	-  gradCPT task 
		-  Performance measure: $d^i$ or sensitivity = hits–false alarms 
			-  How accurate is each person taking into account tendency to just hit the button 
		-  fMRI collected while they were performing the task 
	-  Resting state fMRI data 
-  Beijing participants: 113 kids & teenagers with ADHD and typical controls (mean age 11 years) 
	-  Resting state fMRI data 
	-  ADHD-RS scores (inattention & hyperactivity/impulsivity)

*Generalizations*: from Yale to beijing, from adult to child, from attn network to ADHD scores

##### Variables
**Independent/Predictor** 
-  gradCPT conditions: Go vs. Nogo (city vs mountain) 
-  Choice of 268 network nodes 
-  Participant group (neurotypical adult, neurotypical youth, ADHD youth) 
-  Summary measures of network connectivity based on BOLD time courses 
	- Positive network strength 
	- Negative network strength 

**Dependent/Outcome** 
-  BOLD response 
-  Performance on gradCPT ($d^i$) 
-  ADHD-RS Score  (parent's opinion of attnl ability)
-  Summary measures of network connectivity based on BOLD time courses 
	-  Positive network strength 
	-  Negative network strength

Variables operationalize cognitive processes 27/2/25 PSYC 365: Class 14 17 -  $d^i$ (performance on gradCPT) -  ADHD-RS Score -  SAN models: Built from correlations between BOLD time courses -  Capacity for sustained attention -  ADHD symptoms (associated with problems with sustained attention) -  Neuromarkers of high and low levels of sustained attention ability

#### **3 step analysis**
1. Derive a network of regions whose connectivity strength predicts gradCPT task {behavioral measure} performance ($d^i$) in Yale group 
2. See if stat. model based on net strength while performing gradCPT can be applied to resting-state data to predict gradCPT task performance {networks that fire together at rest tend to fire together at work}
3. See if SAN model can be used with resting state data to predict ADHD scores

*What is Sustained Attention Network (SAN) model and how was it derived?*
-  The SAN model is a brain network based statistical model 
	-  You take correlated activity across a bunch of regions across the brain and reduce it to two numbers (summary statistics) 
	-  Those numbers reflect degree of connectivity in a brain network associated with the capacity for sustained attention 
	-  SAN model uses brain network scores to predict an individual’s attention performance

*How do we get these two numbers?*
##### Step 1
Assess what patterns of brain connectivity are relevant to attention 
	I. Measure correlations between pairs of nodes in each participant 
	II. Test which patterns of connection between regions is linked to good and bad gradCPT performance between participants

**I. Measuring correlations**
Choosing nodes (regions) across canonical networks
- Node = Avg all voxels in brain region →  see how BOLD incr. & decr. 
- Each edge between nodes is thin/thick depending on the level of correlation
- Matrix of correlations: Arrange edge strengths–temporal correlations–into matrix. 

**II. Patterns of connection** 
Correlate edge strength with good and bad gradCPT performance 
-  Positive tail: Edges most correlated with good performance (757 edges) – it’s a network. 
-  Negative tail: Edges most correlated with bad performance (630 edges) – it’s a network 
-  Network strength: *Summary statistic* calculated for each tail by adding up all of the correlations
	- Sum up corrl of all edges in each tail – pos network strength → high attn, vice versa
	- Both measures of network strength corrl w $d^i$

SAN model = model of relationship btwn network strength and $d^i$ scores 

Cross validation = taking one participant out, calculating best prediction w/o them, using groups of edges to calculate summary score for left out person, then using regression model to predict all but left out person's $d^i$.

**Result of cross-validation:**
Both pos and neg networks highly corrl w/ gradCPT performance (r>.8)
- Internal validation: prediction from task connectivity


##### Step 2
- See if SAN model, based on brain networks identified during performance of the gradCPT task, can predict gradCPT task performance from tail scores calculated from *resting state* data in the same people

**Correlation using resting state data**
![[Screenshot 2025-03-04 at 4.50.19 PM.png|300]]
- Controlling for age, IQ, and hyperaactivity 
- Not as high as gradCPT, but still good: r>.4
##### Step 3
- See if you can use the SAN model (created from Yale data during gradCPT task) to predict ADHD scores in kids and adolescents in Beijing based on network scores calculated from their resting state data.

**Correlation between SAN and ADHD score**
![[Screenshot 2025-03-04 at 4.52.21 PM.png]]
- Negative corrl between sustained attention - $d^i$ score - and ADHD score
- Prediction works!

![[Screenshot 2025-03-04 at 4.53.34 PM.png]]
*High Attention Network*  
- connections between motor & occipital cortex & cerebellum 
- connections between subcortical/cerebellar, motor and visual *networks* 
*Low Attention Network*
-  connections between temporal and parietal regions & between hemispheres in temporal and cerebellar regions 
- connections within subcortical and between subcortical and frontoparietal *networks*

#### Rosenberg Summary 
- SAN model allows functional connectivity between many nodes from many canonical networks to predict cognitive ability across different populations 
- “Holistic neural index of sustained attention" 
- Benefits of resting state data 
- Can be collected quickly and easily 
- Predictive not just descriptive 
- Not confounded by differences in task performance due to age or training 
- Meaningful link between ADHD and sustained attention 
- Does NOT suggest that attention is a unitary process!

- Sustained attention emerges from coordinated activity all across the cortex, subcortical structures and the cerebellum 
- Underlying networks extend far beyond traditional regions and networks 
- Serves one of the main goals of human neuroimaging: 
	- Identify *neuromarkers* that predict educational or health outcomes 
- Results suggest ADHD is a continuum of neural and behavioural function


> [!note] Clarifying notes from Brandon:
> - The upper tail of the SAN is a measure of **the nodes that are most correlated given _high_ sustained attention performance (High attention network).** 
> - The lower tail of the SAN is a measure of **the nodes that are most correlated given _low_ sustained attention performance (Low attention network).**

On slide 43's question, the correct answers are both C and D (Continuum of neural and behavioural dysfunction _and_ disorder in sustained attention and cognition). I've updated the version of the slides with notes to reflect this.

## Class 14 - Motivation and Emotion, Inman et al
03.04.25
[[Inman_Amygdala_In_2023-2.pdf]]
[[Class14_365_2025_notes.pdf]]

### Motivation and Emotion

-  Describe four evolutionarily conserved basic emotional/motivational systems 
- Explain ways in which amygdala and mid-brain dopamine systems play a role guiding motivated attention 
- Evaluate factors that influence individual differences in vulnerability to anxiety, addiction and depression

**Motivation**: The impulse to approach/avoid smth that rewards/punishes
- *Urge towards action*
**Emotion**: Physiological sensations of emotional arousal and subj.v feelings that go w/ them 
- *Subjective experience*

#### Basic brain systems for motivation and emotion
1. Circuits for responding to major life-changing events
	1. Amyg. and basal g. 
2. Organize behav responses
3. Exchg info w fronto-parietal sys important for high order consciousness cogn
4. *Change sensitivities of sensory sys relevant for dealing w those events*

Like dorsal attn network; attune sensory cortices to salient/relevant stim
Best understood, most reliable circuits: "grade-a " emotional sys (Panskepp)
→ ![[Screenshot 2025-03-09 at 12.15.19 PM.png|300]]

#### Amygdala
Hub; connects to many other regns
Tagging what's biologically important and guiding attn/memory 


> [!NOTE]  *Review Inman paper*
> - What are key regions that are nodes in amyg-networks for its function in emtnl percept and mem?
> -  What amygdala functions have been demonstrated by case studies from the last 3 decades? 
> - What is unique about the structure of the amygdala and what does that mean for its multiple functions?
> - How do the authors summarize the role of the amygdala in present perceptions? 
> - List findings from lesion and stimulation studies they use to support this claim. 
> - How do the authors describe the role of the amygdala in prioritizing certain memories? 
> - List findings they use to support this claim 
> - How do the authors claim that the amygdala’s role in perception and memory reflects its unique structure?

Amygdala solves the problem: "How can a limited-capacity information processing system that receives a constant stream of diverse inputs selectively process those inputs that are the most relevant to the goals of the animal?"

Emotional relevance is subj; e.g. depression biases towards neg. stim. 
~Universal = emotionally salient

##### SP
**SP** lost amyg later in life (compared to **SM** who lost in childhood)
- Bilat amyg lesions, R.amyg removed and L damaged due to seizures
- Funny, likeable, avg IQ
- After surgery, participated in many studies by researchers Liz Phelps and Adam Anderson

*Attentional blink (AB)*
- When attending to multiple target stim., takes .5 second to be able to register target 2 immediately following target 1–if T2 follows <.5 second after, we don't see it 
*Emotional sparing/AB sparing*
- Reduced attnl blink when T2 is high in emotional arousal–measure of attnl bias
- Shaped by experience; words/images relating to personal traumatic experiences are more emotionally salient
	- Combat related words for soldiers w/&w/o PTSD, & civilian controls – combat words for those w PTSD activated *visual cortex*

**SP: Impaired Emotional Attention**
- "SP does not have this superpower for detecting emotionally relevant words that the rest of us do. This was true for both positive words and negative words. To rule out the possibility that S. P. was just poor at perception in general, the visual similarity of targets and distractors was manipulated, so that the targets would stand out from distractors to a greater or lesser degree"
	- Q: What kind of attentional process does manipulating visual similarity get at? (bottom up) What attentional network is responsible? (VAN). Like controls, S. P. showed AB sparing for words that were visually easier to perceive -- in contrast to impaired AB sparing for emotional words. The conclusion was that (3) the amygdala influences selective attention for emotional relevance but not perceptual salience

But: *No impairment to **feeling** emotion!*

#### Fear system
**Fear**
- Identifiable threat in the near future
- Strong threat; amyg signals to ANS→ hypothal, heart rate, BP incr.,  etc. 
**Anxiety**
- Overdrive fear system
- Also activates stress response to lesser degree
	- Chronic stress = incr. inflammation, exacerbate illness
- Amyg. more sensitive to threat than reward
- Leads to elevated physiolog. response, sensory processing, memory, rumination
- Attn captured by threatening stim. 
- "Capture followed by avoidance" -- once you notice threatening thing you avoid it
- Can cause attnl bias; misinterp. nonthreatening stim as threatening

Attentional biases cause feedback loops; *avoiding* situations and not learning how to deal w/ them, attn more attuned to threatening stim, rumination incr. anxiety more, further attunes attn

#### Summary


- Grade A Blue Ribbon emotional systems evolutionarily conserved 
- Amygdala: “tagging” emotional salience and routing information to other brain regions to enhance attention (& learning & memory) 
	- Attuning
- Loss of amygdala can result in impaired attention to what’s emotionally relevant 
- Amygdala is key for tuning attention to what is relevant in the world based on experience
- In anxiety and PTSD attentional bias to threat is extreme, and amygdala systems can go into overdrive and hurt more than help 
- Result: Seeing threat everywhere at the expense of safety and reward! 
	- Attention is limited after all

## Class 15 - MT2 Review
https://ubc.ca.panopto.com/Panopto/Pages/Viewer.aspx?id=221e6a33-024d-4546-bc07-b25f0138c969
[[MT2_review_2025_AM_06March2025_notes.pdf]]
- Point form 
- Key details 

Short answer; 
- Lecture content
- Tips doc. 
- Extra content, other themes, critiques

Older material; 
- Practice questions
- Review lecture slides

##### Predictive coding

> [!info] Learning Objectives
> - Describe predictive coding models
> - Eval. fMRI evidence from Egner for PC vs bottom up feature detection 
> - Discuss what PC means for our understanding of how our brains work & the grasp we can have on reality

**Forward model (top down)** 
- Representation/model of the world
- Generates predictions; '*representational units*' encode expectation of a given stim
- Tries to "explain away" sensory signal

**Error signal (bottom up)**
- Sent upward based on match btwn model and sensory info
- ONLY prediction error gets passed forward, not actual signal 
- '*Error units*' encode mismatch btwn predictions and bottom-up evidence

*Goal: minimize prediction errors*

##### Rosenberg et al - review
**Problem: No *summary index* of attention**
- Attn is key for percep/cogn
- Diff types of attnl processes have too many diff measurement types
- None are good measure of individual attnl ability
**3 Assumptions** 
1. Individual differences in sustained attention will be reflected in complex patterns of correlated BOLD activity across brain regions 
2. These patterns will be observed both when you’re doing a task and at rest 
3. If we can distill a signature of these patterns we should be able to use them to predict attention ability in a completely different set of people

**Question:** What atttional processes are involved in sustained attention?
 -  Information selection 
 -  Inhibition of unselected information 
 -  Enhancement of selected information 

- **Big picture question:** Can we find a neuromarker, or brain-based measure of general attentional ability?
- **Specific question:** Can we get take a data-driven approach to pulling out patterns of network activity to give us a marker of sustained attention that will generalize across populations?

**Methods** 
-  Yale participants: 25 students 
	-  gradCPT task 
	-  Resting state fMRI data
-  Beijing participants: 113 kids & teenagers with ADHD and typical controls (mean age 11 years) 
	-  Resting state fMRI data 
	-  ADHD-RS scores (inattention & hyperactivity/impulsivity)

In the scanner, participants saw images of cities and mountains. 
-  Their task was to press a button if they saw a city scene, NOT a mountain scene.
-  *d’ or sensitivity was used as the measure of their performance = # of hits - # of false alarms.* 
-  Parents completed the ADHD-RS questionnaire - a measure of the participants’ degree of ADHD symptoms


**Goal:** Identify a neuromarker of sustained attention based on whole brain intrinsic connectivity 
-  Step 1: Derived a network of regions whose connectivity strength predicted gradCPT task performance (d’) in Yale group. Created brain scores of connectivity strength (high and low attention) that predict d’.
-  Step 2: Examined if statistical model based on network strength while performing gradCPT can be applied to resting-state data to predict gradCPT task performance.
-  Step 3: Examined if SAN model can be used with resting state data to predict ADHD scores in kids and adolescents in Beijing

**The SAN Networks** 
*High Attention Network* -  Connectivity pattern correlated with high performance on gradCPT (Yale Students) and low ADHD scores (Beijing kids) 
*Low Attention Network* -  Connectivity pattern correlated with low performance on gradCPT (Yale Students) and high ADHD scores (Beijing kids)

> [!note] You should know 
> -  What is the main advantage of using the SAN model as a neuromarker? 
> -  What is the main advantage of using resting state data? 
> -  What do the authors say are the main are the two main implications of their findings for understanding of neural underpinnings of sustained attention?


##### Egner et. al. - review
- **Big picture question:** Does PC explain vis obj recognition better than classic hierarchical feature-based models? 
- **Research question:**  Does BOLD activity in the FFA reflect responses to expectation + surprise? Or just face features? 
- **General Hypothesis:** FFA activity will be an “additive function” of expectation and surprise. 
- **Alternative hypothesis:** There will always be more FFA activation to faces 
	- Expectation and surprise will not matter!

*Participants?* 
*IV/DV?*

**PC Model beat feature detection model w fit to data**
Assumed surprise contribted = to expectn; actually, PC model that fit best was 2:1 surprise:expectation 

**Conclusions:** PC describe process of vis inference >> feature detectn & encoding prediciton and erorr is gen. charactstc of how brain works

#### Attention

> [!info] Learning Objectives
> - Covert vs overt attn
> - Classic models of selective attn and brain sys 
> - Attnl set: defn & expln of neuronal mechanisms

**Selective**
- What we perceive + what we are aware of
- Innattenl blindness
- "spotlight"
**Sustained**
- Choosing what to focus on and surpressing else
- Change blindness
- "blinders"

**Overt**
- Gaze focused & fledxible
- Gaze & focus align
- Attn guided by eyes
**Covert**
- Gaze focused on specific pt
- Gaze & focus don't align
- Attn guided by mind

##### Selective
- Covert or overt
- Active process
- Filter and focus on relevant stim; discern important bckgd info 
- *ID targets*
	- Based on goal & temporal relevance, salience factors
	- "Distinctness" determined by 2 attnl sys → top-down & bottom-up

##### Attnl systems
**Top down**
- Voluntary, conscious, goal directed
- Directly controlled
- Requires use of *attnl set*
→ **Dorsal Attn Network (DAN)**
- Frontal eye fields (FEF) & *intraparietal sulcus*
- Maps to regions of space/distinct features

**Bottom up**
- Invol, feature based
- Automatic, response
- Captures attn w/o attnl set
- Often contrary to goals
→ **Ventral Attn Network (VAN)**
- Ventral frontal cortex & *temporoparietal junction (TPJ)*
- Involved in repsonses

*DAN & VAN communicate w/ each other & modulate V1*

**Attnl set**
- *Mental template used to identify object*
- Separate relevant stim categories
- ID shared features btwn template & stim
- *Cued by FEF & IPS*

**Biased competition**
- *Activation of neurons tuned to task relevant stim*
- Used to create attnl set
	- Target neurons preemptively fire
	- Competing neurons suppressed
- Prime & regulate activity
- Primarily in DAN

**Targeting**
Red X jumps out; ventral
Pattern recognition, searching; dorsal (green Os/red Ns task)

##### Sustained attn
- Used to attend to low attnl/mundane stim for duration
- Measured using SART (sustainedd attn to response task)
- Performance can be marker for ADHD & impulsivity


##### Connolly et al - review
- Recognition memory task
- Rating stimulus similarity
	- How people categorize animals/insects
- RSA: EV/V1 doesn't map to animal categories; Up ventral stream, esp LOC & IT, do line up w/ categorizations
- Representations in our brain map to defined categories in the world; show up at later parts of visual stream
- *Shows us how to use RSA to capture how we categorize info. abt diff things in world*

RSA fine grain patterns of stim at "lower level" aka more specific categorizations

##### Inman paper
Multifaceted influence of amygdalae on behavior - You should know the key regions from this figure that are key nodes in networks the amygdala participates in for its functions in emotional perception and memory
![[Screenshot 2025-03-10 at 1.34.41 PM.png|400]]

**Be able to answer:**
1. What three amygdala functions have been demonstrated by case studies from the last 3 decades? 
2. What is unique about the structure of the amygdala and what does that mean for its multiple functions? 
3. How do the authors summarize the role of the amygdala in present perceptions? 
	1. List two findings from lesion and stimulation studies they use to support this claim. 
4. How do the authors describe the role of the amygdala in prioritizing certain memories? List two findings they use to support this claim 
5. How do the authors claim that the amygdala’s role in perception and memory reflects its unique structure?

#### Emotion, Motivation, and Attention

> [!info] Learning Objectives
> 1. Describe 4 evol. conserved emotional/motivational systems
> 2. Explain ways in which amyg and midbrain sys play role in guiding motivated attn
> 3. Eval factors that influence individ diff in vulnerability to depression and anxiety
> 

**Motivation: approach/avoid**
**Emotion: physiological response**

**Theories of Emotion**
Basic emotions theory: we have universal emotion sys that are discrete from each other
Other theories: emotion can be defined by valence, approach/avoid, arousal  
*Panksepp*: Frames as complex sets of behavior; Blue Ribbon sys

##### Blue Ribbon Grade A Systems
- *Seeking*: pos reward, approach → hope, anticipation, curiosity
- *Fear*: destruction, avoid → alarm, foreboding
- *Rage*: goals thwarted, approach → hate, anger
- *Panic*: loss of social reward, withdraw & approach → separation, loneliness, clinginess

##### Amygdala
*Hub for motivated/emotional attn*
- Important "node"
- Tags what is biologically important
- Affected by past experience
- Selectively processed according to however they are most relevant to goals
	- Selective attn by emotional salience
	- Modulates ventral vis sys, like DAN

**SP**
- Intact emotional experience compared to controls
- Didn't show emotionally biased attn, diff classical conditioning

Amyg not necessary from subj feeling of emotion
# Midterm 3
## Class 17 - Dopamine (03.13.25)

[[Class17_365_2025_notes.pdf]]

> [!example] Readings: 
> - [[Anderson et al. - 2016 - The Role of Dopamine in Value-Based Attentional Orienting.pdf]]
> 	- [[Tips for reading Anderson et al..pdf]]
> - [Crimes against dopamine](https://medium.com/the-spike/the-crimes-against-dopamine-b82b082d5f3d)
> - [Has Dopamine got us hooked on tech?](https://www.theguardian.com/technology/2018/mar/04/has-dopamine-got-us-hooked-on-tech-facebook-apps-addiction)
> 

> [!info] Learning Objectives
> - Explain ways in which amygdala and mid-brain dopamine systems play a role guiding affectively-biased and motivated attention 
>  - Evaluate factors that influence individual differences in vulnerability to anxiety, addiction and depression
> 

DA system important to study bc of relationship to addiction

Reward-biased attn 
- Approach cued by beer picture

**Seeking:** 
- Desire, hope, anticipation
- Panksepp: approach = “stimulus bound appetitive behavior”
- DA = wanting not getting
- Incentive salience - cue stands out bc assc w/ reward, similar to emotnl salience
- Cue → craving → automatic actn

### Reward system
**NAcc:** 
- Reg of V.stri in BG, key in mesolimbic DA sys
- DA released onto NAc neurons when you expect reward or encounter unexpected reward
- Reduce firing (“sulk”) when you don’t get an expected reward
- Also: 
	- Caudate nuc 
	- Putamen

**Dopamine (DA)**
- Produced by SN & VTA (mesolim DA pathway)
- Tonic: Wanting/seeking
- Motivates to get out of bed, get out there to get general rewards
- Phasic: Prediction error, reward expectation 
- Fast bursts of DA produced by prediction error & signals reward expectation
- Incentive salience: when cue acquires assc w reward and triggers craving → attend habitually

DA Hype – [Has Dopamine got us hooked on tech?](https://www.theguardian.com/technology/2018/mar/04/has-dopamine-got-us-hooked-on-tech-facebook-apps-addiction)
- “Celebrity molecule of silicon valley”
- “Tech companies understand what causes dopamine surges in the brain and they lace their products with ‘hijacking techniques’ that lure us in and create ‘compulsion loops’.”

### Anderson et al 2016
##### Pre-study questions
**Big Picture Question** 
- What is the role of dopamine in attentional biases to cues signaling reward?

**Background** 
- DA is important for learning that certain cues predict reward  
- Cues signaling reward capture attention, even when not relevant to “top-down” goals

**Specific Question**
- What is the role of dopamine in maintaining the attentional salience of reward cues even when they no longer predict reward

> So once an attentional habit is developed cues signaling reward capture attention, even when not relevant to top-down goals. The specific question is really important when you think of relapse.

> That's why if you're in in rehab you're not supposed go to old spots you used to spend time in, hang out with old friends... Too much incentive salience in cues that trigger your old craving

##### Training
- What is the orientation of the bar in the red OR green circle?
- Raise your right hand if horizontal, left hand if vertical
- (red circle) Correct; + $1.50 – red high reward
- (green circle) Correct; + $0.25 – green low reward
> By the time you’re done every cell in your body will know that red predicts high reward and green predicts low reward. Then you will go home, sleep, come back the next day, and have a radioactive tracer injected into your arm. Then the fun really begins!

PET next day: Scan A has distractors, Scan B doesn’t

##### Tracer measuring DA availability
- [11^C] Raclopride. A radioactive tracer for measuring DA availability 
	- 11 Carbon: Radioactive tracer that labels the Raclopride 
	- Raclopride: DA Antagonist: Binds to DA receptors (D2/D3) & changes availability  
	- DV: % Change in Raclopride Concentration: 
		- Distractor Present > No Distractor = more DA release in the presence of distractor
	- When you measure raclopride binding twice in two different PET scans, you can interpret the difference in the amount you measure between the scans as a difference in DA release between Scan 1 and Scan 2. 
- If the index of receptor availability, the nondisplaceable binding potential (BPND), in the experimental condition is different from the baseline BPND, then the observed changes in BPND are attributed to changes in endogenous [DA]. Decreases in BPND relative to baseline indicate increases in [DA], and increases in BPND relative to the baseline BPND indicate decreases in [DA]. So if there is less binding potential it means more receptors are already taken up with DA. The Raclopride has nowhere to bind to.
#### Variables
**Independent variables:**
- Training: IV was different levels of reward associated with a specific colour. 
- For Test Scan: Distractor present and no distractors present. 
	- And within distractor present: Rewarding distractor absent, High reward distractor present, low reward distractor present. 
- Region of interest was also an independent variable. 
- They looked at 10, although they focused on Putamen and anterior and posterior caudate. 

**Dependent variables:** 
- Reaction time in indicating the bar orientation. 
- PET measures of DA availability (raclopride concentrations, or “nondisplacable binding potential”) 

#### Results: Value-Driven Attentional Capture (VDAC)
- If you’re more distracted by previously rewarded color, slower to report bar orientation in target shape


![[Screenshot 2025-03-17 at 7.53.05 PM.png|450]]
Training: 
- Response time faster for high value condition (index of appetitive conditioning), RT goes down at same rate for both value cond.s 
Test:
- RT for high val distractor > low val distractor > no distractor
	- Acquired incentive salience
- *Diff between high val and no distractor* = **value-driven attentl capture** (VDAC)

** note; sample size too small for corrl, but they worked hard to control for chance findings
![[Screenshot 2025-03-19 at 10.29.43 AM.png|450]]
Y axis = *difference* between high val distractor reaction time and no distractor RT
X axis = *% change in DA release* between distractor present and no distractor 
More DA released for distractor; more VDAC shown 
→ Two groups shown in graph; those w/ less VDAC & less change & vice versa: 
![[Screenshot 2025-03-19 at 10.33.14 AM.png|450]]
##### Individual differences in VDAC/DA release
- Group 1: More VDAC & more DA release in scan with distractors,  
- Group 2: No or negative VDAC & less DA release in scan with distractors
> This suggests a dissociation between groups: Strong value-driven attentional capture is associated with significantly elevated levels of dopamine, whereas the ability to ignore previously reward-associated stimuli is associated with less of dopamine release in these same regions. 

**Pattern seen across 3 ROI/DA regions**: R pos putamen, R pos caudate, R ant caudate

##### Caudate
- Involv in shifting of cov attn
- Neural response in tail of caud: sensitive to learned val and val based attl captre
	- Communicates w vis. cort
- Caudate modulates vis cort for **habit**
	- DAN mod vis cort for task relevance, amyg mod vis cort for emotional relevance
	- "Anderson suggests – and I agree– that affectively and motivationally biased attention is a habit."

Building a bias: Anderson = first study linking individ diff in behavr to diff in changes of DA w/ learning that builds attnl biases

#### Anderson Summary
 - Attention is captured by objects that previously predicted reward, even when they no longer do 
 - People who are more captured by cues of past reward show more dopamine in the dorsal striatum in the presence of reward cues 
 - Those who are not captured *show less* DA in the presence of reward cues: Maybe they suppress? 
 - **Habit**: DA signaling in dorsal striatum is important for involuntary motivated attention linked to addictive behavior.

### Motivated attention
 
*Evaluate factors that influence individual differences in vulnerability to anxiety, addiction and depression*

#### Depression
Seeking/reward system dysfunctionally low
***No VDAC*** 
- Due to inability to learn assc between shape color and reward? Or just not salient
→ Learning = controls: *depression linked to lack of VDAC, not to a problem with reward learning*
### Dopamine take-home
- DA circuitry is important for acquiring incentive salience leading to attentional biases for reward 
- Individual differences in DA availability are related to differences in reward-biased attention 
- Reward-biased attention is a marker of both addictive behaviour (more) and depression (none)
## Class 18 - Hippocampus & memory (03.18.25)

> [!example] HW
> [[Cognitive Neuroscience_ A Very Short Introduction-Passingham.pdf#page=69&selection=0,9,0,9|Passingham, Chapter 4]]

[[Class18_365_2025_notes-1.pdf]]

*Anderson or bird will be short answer*
### Wrap-up: Attention
- Selective attn 
	- Classic; top/bottom
	- DAN/VAN modulate activity in sensory corts
	- Motivated attn: aml rel and expct of reward (DA) guide attn via amyg & BG mod
		- Pattersn fo attl bias linked to anxiety, depr., addict.n

### Memory
Endel Tulving; multiple mem sys (not just short/long) '72

**Implicit**
- Procedural 
- Performance of skilled act
- Conditioning
- Memory for emotl relevance revealed by actns

**Explicit**
- Semantic
	- Facts
- Episodic
	- Events - "mental time travel"
- Autobio mem
- Prospective mem
	- Performance of future actn

#### Hippocampus

> [!info] Learning Objectives
> - Explain the concept of a cognitive map 
> - Evaluate evidence for role of hippocampus in human navigation 
> - After the next series of lectures, link what we know about the role of the hippocampus in spatial navigation to its role in episodic memory

- Episodic mem & imagine future 
- Conscious mem in time sequence
- Crucial for navigation: mental maps - link time & spacial roles

##### Rat nav. 
Video: watch the firing of hipp *place cells*:
- Diff clusters of neurons fire at diff parts of maze → mental maps
- Not topographical, nearness of cells ≠ nearness of "fields"/spaces
- Place cells can change firing patterns suddenly; "re-mapping"

*Conundrum:*
- We know how rat space navigation works
"On the one hand we had lots of data for how the hippocampus works in spatia; navigation in rats. For example in addition to place cells we now also know there are a number of other types of cells in hippocampus and other regions of the medial temporal lobe that play a role in navigation. Grid cells in the entorhinal cortex which is in the anterior temporal lobe next to the hippocampus, and sends the hippocampus information. Rather than tagging specific locations, as place cells do, grid cells organize space into a gridlike map that is used in any environment. So where place cells will remap, these grids that organize space hold constant. And there are also head direction cells and border cells which track the edges of a spatial location.[1] On the other hand, we had human lesion data indicating the hippocampus was vital for episodic memory, or the ability to call up and relive or replay events. Recently researchers have begun to extend the idea of cognitive maps, first introduced in relation to rat spatial navigation, to episodic memory, or the ability to travel through time as well as space."

##### Cognitive map hypothesis
Brain builds rep/mental map of spatial env. to support mem and guide future act.n
- *Landmarks*: link mental map to sense info - location in relation to smth perceived
	- Vis cort reg play role in ID landmarks; inc.l PPA (passingham) in v.vis.cort, sensitive to *scenes* 
- Not identical to actual space -- schemas: *mental scripts*
- Hipp: *planning routes*

#### City navigation
##### Pre-study questions
**Research questions:** 
1. When might the hippocampus be most required during an ongoing period of navigation? 
2. Which specific navigation processes might it be most important for?

##### Experimental design; **Reading taxi drivers’ minds**
- 20 London taxi drivers (mean age 49) 
- fMRI scans 
- Realistic VR of London 
	- Ecolg.cl validity: active rather than passive, resembles actual driving, includes known landmarks
- Had to navigate to a destination in response to customer requests 
	- During "drive," interruptions and changes to navigation
- After scan watched video of route and reported what they were thinking

##### Results 
![[Screenshot 2025-03-19 at 11.11.30 AM.png|400]]
After; ppl watched video of drive and were interviewed about it- "read" thoughts - can connect specific thoughts at points in time to areas of activation 

![[Screenshot 2025-03-19 at 11.10.25 AM.png|450]]

**Summary**
- Brief activation in hippocampus important for planning a route to a very specific destination 
- NOT when alterations to the route are made on the fly or to update where they are in relation to goal 
- Theory: Hippocampus retrieves relevant spatial information from a “cognitive map” 
- But is this universally true in navigation?

Q: Why might you not need the stored map when making decisions on the fly? 
They say, based on previous research,:
>  Generating the initial vector, updating the most efficient route, and observing landmarks to update the current vector to the goal, might all be likely candidates to show increased activity in the hippocampus. Whilst the first prediction is borne out by the current results, the latter two are not. Thus, our results provide an empirical basis from which models of hippocampal processing might be refined.

#### Embodied, extended, relational cognitive maps
- Enactivism: cogn emerges *dynamically* thru bodies embedded in env
- Extended cogn: cogn is distributed btwn humans, other humans, and tools we use
- Fernandez-Velasco & Spiers, 2024: Tradnl navigation strategies are both local and insep from a *larger cultural system* 
- Interdisc approach: 
	- Phenomenology
	- Cogn ethnography
	- Brain imaging
	- Gamified experiments
	- Survey instruments
	- Thematic analysis

##### Wayfinding outside of WEIRD contexts
- Celestial navigation 

> "The Gwich’in celestial scheme is paradigmatic of most traditional navigation in that it is both local and inseparable from a larger cultural system: to use it one must learn particular constellations, place names, and mythology. Using such systems, humans show remarkable feats of navigation across a variety of environments, from trekking dense tundra, to sailing vast oceans, to negotiating the streets of sprawling cities. Humans exploit a rich diversity of strategies to achieve this. While experimental research in the laboratory has helped uncover the cognitive features and brain systems underlying navigation, most studies test western participants in highly controlled settings and, thus, ignore the heterogeneity of cultures and environments that humans navigate."

Allo- vs. ego-centric (in relation to first-person)

**Main Takeaways** 
- Traditional cognitive science has overlooked: 
	- Non-visual senses 
	- Visualization techniques 
	- The role of language and naming 
	- The role of navigation tools/artifacts 
	- The role of culture and local knowledge 
- Broader view of navigation “*moves away from a narrow focus on internalized memory representations of spatial locations toward an understanding of navigation as a dynamic, action-oriented skill involving a heterogenous set of cognitive resources and heuristic.*”

**The Hippocampus In Navigation** 
- Hippocampus important in laying down cognitive maps, or a more abstract representation of a physical or metaphorical landscape 
- Hippocampus is active in calling up detailed representations of spatial information 
- It is involved particularly in beginning stages of goal-directed navigation – planning routes to specific goals 
- What is its role in other systems of wayfinding?

*This lecture; hippocampus in spatial navigation*
*Next; hippocampus in episodic memory*

## Class 19 - Episodic memory
[[Class19_365_2025_notes.pdf]]


> [!info] Learning Objectives
> - Give examples of retro and anterograde amnesia
> - Evaluate effects of extreme medial temp lobe dmg on episodic memory and sense of having a self


**Retrograde amnesia**
- Cannot recall events in lives that occurred prior to some critical event that affected their brain - accident/stroke
**Anterograde amnesia**
- Failure to form new memories after critical event

#### Stages of memory
1. **Encoding**
	1. Initial perception of event
2. **Consolidation**
	1. Strengthening and making more enduring over time
	2. Synaptic level & systems level
3. **Retrieval**
	1. Calling back later

***Reconsolidation***
- When memory is changed at retrieval; memories become labile/unstable when retrieved --- new info integrated before reconsolidation → update memories but also create false 
