[[syllabus_365_2024W-1.pdf]]

| PSYC_V 365-002 - Cognitive Neuroscience | Lecture | Tue Thu <br>3:30 p.m. - 5:00 p.m. <br>MATH-Room 100 | Brandon Forys | 2   |
| --------------------------------------- | ------- | --------------------------------------------------- | ------------- | --- |
### Readings and Assessments

| 1   | 01.07.25 | Introduction/Syllabus Module Syllabus                                                                                               |
| --- | -------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| 2   | 01.09.25 | Cognitive Neuroscience: The Good, the Bad, and the Ugly Passingham Chap 1; How to Read a Scientific Paper for Non-Scientists        |
| 3   | 01.14.25 | Quiz: Cognitive Neuroscience methods Neuroanatomy module; Poldrack & Farah, 2015                                                    |
| 4   | 01.16.25 | fMRI: Workhorse of Cog Neuro Dimsdale-Zucker et al., 2018, section 1 only                                                           |
| 5   | 01.21.25 | Recognizing objects Part 1 Passingham Chap. 2 to pg. 58 (Classifying Objects); Brain facts: How AI helps us understand human vision |
| 6   | 01.23.25 | Recognizing Objects Part 2 Neural networks made easy; Bowers et al., 2023 (pgs. 1-19)                                               |
| 7   | 01.28.25 | What is special about faces? Harada et al., 2020; Cracking face code                                                                |
| 8   | 01.30.25 | Review                                                                                                                              |
| 9   | 02.04.25 | **Midterm 1**                                                                                                                       |
| 10  | 02.06.25 | Guest lecture (to be announced) TBD                                                                                                 |
| 11  | 02.11.25 | Classifying objects Passingham Chap. 2 pg. 58 (Classifying Objects)                                                                 |
| 12  | 02.13.25 | Predicting Perception Egner, Monti, and Summerfield, 2009 17-21 Feb NO CLASS – Reading Week                                         |
| 13  | 02.25.25 | Selecting attention Passingham Chap. 3; Videos                                                                                      |
| 14  | 02.27.25 | Sustaining attention Rosenberg et al., 2016                                                                                         |
| 15  | 03.04.25 | Emotion, motivation and attention Inman et al., 2023                                                                                |
| 16  | 03.06.25 | Review                                                                                                                              |
| 17  | 03.11.25 | **Midterm 2**                                                                                                                       |
| 18  | 03.13.25 | Reward and attention (& learning) Anderson et al., 2016; 2 Dopamine blogs                                                           |
| 19  | 03.18.25 | The Hippocampus: From space travel to time travel Passingham Chapter 4; Fernandez- Velasco & Spiers, 2024                           |
| 20  | 03.20.25 | Episodic memory How to See a Memory                                                                                                 |
| 21  | 03.25.25 | Rehearsing and retrieving memories Bird et al., 2015                                                                                |
| 22  | 03.27.25 | **Midterm 3**                                                                                                                       |
| 23  | 04.01.25 | Final projects                                                                                                                      |
| 24  | 04.03.25 | Final projects                                                                                                                      |
| 25  | 04.08.25 | Final projects                                                                                                                      |




# 01.07.25 Lecture 1
[[Class1_365_2025.pdf]]
Understanding relationship between brain activity and cognitive processes

# 01.09.25 Lecture 2
[[Class2_365_2025.pdf]]
[[Raff How to read and understand a scientific paper a guide for non-scientists|Raff how to read]]
[[Cognitive Neuroscience_ A Very Short Introduction-Passingham.pdf|Passingham Ch2]]
[[Class3_365_2025.pdf]]

# 01.30.25 Lecture 8

**SHORT ANSWER QUESTION**  
Answer the following based on the paper we read by Harada et al., 2020, which used fMRI to examine  
questions related to face perception and race/culture, as well what you know from lecture material  
about the paper (30 points).  

- **A. What was the big-picture question that motivated the study? (1 pt total)**  

- **B. Background (6 pts total)**  
	- *I. Describe one thing that previous research, described in the Introduction of the paper, has taught us about the influence of culture on responses to facial emotion and one set of findings described in the paper that support that knowledge. Your answer for the  second part of this question (about the set of findings) should elaborate on your answer  in the first part of this question. (4 pts)* 
	- Previous studies have shown in-group affects on bilateral amygdala response. 
	- *II. What two self-construal styles have been identified by cultural psychologists and what are the main characteristics of each? (2 pts)*  
- **C. Research Questions and Hypotheses (3 pts total)**  
	- *I. What was the main research question? (1 pt)*  
	- How do Japanese bicultural individuals (raised in individualistic culture but with connections to collectivistic) compare to Native Japanese (collectivism) in amygdala response to racial in and out group faces? ("That is to say, what neural modulation in the amygdala would be observed in Japanese-American individuals, who are very familiar with Caucasian-Americans’ faces while they have a similarity of physical appearance to native Japanese people, when they were shown facial emotional ex- pressions of Caucasians and Japanese?")
	- *II. What were two hypotheses put forward by the authors? (2 pts)*  
	-  Bicultural (Japanese American) individuals would show greater amygdala response to Japanese faces than Caucasian Americans, and "collectivistic tendencies would be related to neural responses of intergroup negative facial expression."
- **D. Methods (2 pts total)**  
	- *I. How did they define group membership? (1 pt)*  
	- Japanese-Americans were born and/or raised from a young age in America, either first-generation or second-generation. Japanese Natives were born and raised in Japan, and Caucasian Americans. In-group for Japanese Americans was racial in group ie. Japanese. 
	- *II. What was the purpose of the shape stimuli? (1 pt)*  
	- The shape stimuli serve as a control task for a "relatively low-level cognitive process"  
- **E. Results (4 pts total)**  
	- *I. What was the main pattern of findings for the amygdala? What patterns of brain  activity reflected the “cultural in-group effect?” (2 pts)*  
	- There was a significant in-group effect observed in the bilateral amygdala when comparing Native Japanese group with Caucasian-American group. Native Japanese participants showed larger neural responses itn the bilateral amygdala to Japanese faces than Caucasian-Americans did. 
	- Caucasian-American and Japanese participants showed the highest amygdala activities to negative faces of the same cultural and racial members (i.e. in-group members) and the lowest amygdala activities to those of the different cultural and racial group members
	- Japanese-American participants showed neural responses in between the JN and CA groups. 
	- *II. What pattern of brain activity did they find in one particular group of participants when  they looked at the whole brain? (2 pts)*  
	-  Japanese-American participants showed greater activities in the right ventral prefrontal cortex, posterior cingulate cortex extending to precueus and right superior frontal gyrus during processing of negative facial expressions of Japanese than Caucasian-American participants did
- **F. Discussion (4 pts total)**  
	- *I. How do they interpret the midline cortical findings observed in one particular group? (2  pts)*  
	- Likely reflects greater informational demands of self-relevant memory, because their recognition of their racial identity might be automatically strengthened when negative facial expression of racially in-group members was presented.
	- *II. Was their hypothesis about individual differences supported? Why or why not? (2 pts)*  
	- "This result indicates that bicultural individuals respond to negative facial expressions of members from the both cultural groups with slightly attenuated extent as compared to monocultural individuals. We hypothesized that JA individuals would show large amygdala responses to Caucasian negative faces as the same extent as CA individuals would if the in-group bias was due to familiarity of faces learned in their daily life, while they would show large amygdala response to Japanese negative faces as the same extent as JP individuals would if the in-group bias was simply due to their racial identity. The results in the current study did not support either hypothesis"
	- "Although this way might not necessarily eliminate the possibility of remaining variations, it would be still a possible solution and even more useful way by combining with an additional and detailed reliability test such as a ROI analysis for target brain regions that we have done in the current study. In the current study, we excluded the temporal and occipital regions from the analyses only when directly comparing the different facilities, and furthermore confirmed that there was no significant difference of neural activities in the hypothesized regions, that is the bilateral amygdala, in our prior reliability test. Hence, variation in scanner-site performance is not a likely explanation for the variability in the neural activation we observed in the current study."
- **G. Conclusions and limitations (6 pts total)**  
	- *I. How do they describe the overall meaning and importance of the results? (2 pts)*  
	- "Our results show that neural responses in the bilateral amygdala reflected both of in-group biases based on ones’ racial identities and cultural practices, such as ones’ collectivistic tendencies, irrespective of participants’ cultures."
	- "Our results demonstrate that neural responses during the processing of emotional faces could be modulated by different social factors, such as cultural practice and racial identity, and furthermore cultural and racial influences are interlaced especially in bicultural individuals such as Japanese-Americans in the current study."
	- *II. List TWO limitations of the study and explain why they are limitations. (4 pts)*  
	- One limitation of this study involves the generalizability of our findings, as the results were based on only facial expressions of fear and anger.
	- There might be another limitation in the current study, that is a possible variation in the scanner performance between the two facilities which may have led to variations in the neural activation patterns across the two different scanning sites.
- **H. In YOUR opinion (4 pts total)**  
	- *I. What are the larger cultural or societal implications of these findings? Do you agree  with the authors’ conclusions? Why or why not? What do you think is important that  they didn’t think of? (4 pts)*

# Midterm 2

## Class 10 - Guest Lecture

[[Class10_psyc365_guestlecture.pdf]]

> [!note] Suggestion –
> Focus on the descriptions of the tasks used and the key takeaways given for each study. Questions about this guest lecture would appear in the multiple choice section only.

### Study – Reward sensitivity, facial emotion recognition, self-referential processing in MDD & BSD
- **Aim**: Reward sensitivity, facial emotion judgement, self-referential processing in acutely depressed people with MDD + BSD vs healthy control
- **Hypotheses**: 
	- Reward sensitivity: MDD < BSD < CTL 
	- Facial emotion recognition: MDD > BSD 
	- Self-referential processing: MDD = BSD > CTL
##### Monetary incentive delay task
Earning tickets towards draw for $100 prize when they reacted quickly enough (pressing space bar to smily face)
Asked how excited they were about how many tickets they were playing for (# varied)

##### Facial emotion labeling task
Morphed facial continuum from sad to happy 
Shift point: where on continuum participant shifted from identifying face as happy/sad
Slope: rate at which response shifted from happy to sad 

##### Self-referential encoding and memory task
Presented with words descrbiing personal characteristics/trait
Positive/negative self-referential encoding - how many pos/neg words participants chose as describing self

Memory bias: asked after a time what words they could remmeber from the lsit, measuring if they remembered more neg or pos words

#### Results & Key takeaways
**Results:**
- Individuals with MDD had sig. lower anticipatory reward sensitivity than BSD participants (p = .006, d = .73) and control participants (p < .001, d = 1.14) • Participants with BSD did not differ from controls in anticipatory reward sensitivity (p = .454)

- MDD/BSD/CTL (control) groups did not have significant differences in labelling faces as sad vs. happy or sensitivity to the changes in expressed emotions
- Individuals with MDD endorsed sig. fewer positive traits than the BSD (p = .002, d = .80) and CTL groups (p < .001, d = 2.01) 
- Individuals with BSD endorsed sig. fewer positive traits compared to CTLs (p <.001, d = 1.11) 
- MDD and BSD did not differ sig. for number of negative traits (p = .535) or negative self-referential memory bias (p = .311)
**Conclusions:**
Ppl w BSD have more anticipatory reward sensitivity & positive self-referential encoding 
→ May help with ddx-- identifying MDD vs BSD

### Study – Cognitive-Affective processes heterogeneity in MDD & BSD
- Background: Diff.s in cogn-affective processes exist among currently-depressed ppl w/ MDD vs BSD
	- As a group, BSD ascribe more pos traits compared to MDD/CTLs, & have greater anticipatory reward sensitivity 
- **Research question**: How much heterogeneity is there among BSD? – better, more personalized treatment
	- Why might there be heterogeneity? 
		- Depressive episodes can look diff 
		- Prev research has explored that clusters of cogn. affective processing across mood spectrum include participants who are not acutely depressed – these studies looked primarily at facial recognition tasks 
- **Aim**: To identify data-driven subgroups based on cogn-affective processing amongst acutely depressed indiv w/ MDD & BSD

##### Monetary Incentive Delay Task
##### Self-referential Encoding and Memory task

##### Analyses
1. Identify clusters/sub-groups
2. Assess cluster diff in task performance & clinical/demographic var. 
3. Assess proportion of diagnoses across clusters

#### Results
![[Class10_psyc365_guestlecture.pdf#page=22|Class10_psyc365_guestlecture, page 22]]
**Cluster 1: "Negative-Low-Rewarders"**
- Significantly lower anticipatory reward sensitivity & positive self referential encoding, & higher negative memory bias & negative self ref
**Cluster 2: "Positive-High-Rewarders"**

Both clusters scored equiv. on depression matrix

**BSD vs MDD**
More MDD participants were NLRs 
No sign. diff in BSD participants who were NLR/PHR

More controls were PHRs

#### Key takeaways
- NLR & PHR represent distinct cogn-affective processing subgroups 
- There is heterogeneity in cogn-affective processes across mood spectrum 
- Some patients (MDD, BSD) cluster together w/ most healthy controls

*→ Personalized treatment is important*


### Study – Attentional biases in Persistent Post-Concussion Symptoms (PPCS)
Psychosocial factors greater contributers to developing PPCS than injury characteristics
Overlap with chronic pain research
- **Aims**: 
	- To describe correlations between attentional biases as measured on the attentional blink task (in terms of difficulty disengaging from pain-related stimuli), and fear-avoidance model constructs. 
	- To describe correlations between attentional biases as measured on the gaze-time task (in terms of preferential looking towards symptom- relevant stimuli), and fear-avoidance model constructs.
- **Hypotheses**: 
	- Participants who demonstrate greater attentional biases in difficulty disengaging attention from pain-related stimuli will also report greater severity of the fear-avoidance model contructs 
	- Participants who spend more time fixating attention on symptom- relevant stimuli will also report greater severity of the fear-avoidance model constructs (i.e., symptom severity, pain-catastrophizing, and fear- avoidance behaviour)

*Popular ways of measuring attntl biases: emotional stroop, dot probe*, but - poor split test reliability, test-retest, internal consistency, also, had to use tasks that didn't rely on reaction time, since this can also be affected post-concussion

**Groups**: 
- PPCS 
- Recovered
	- Both w/in 1 month of concussion 
##### Attentional blink task
**Standard**
- RSVP stream = rapid serial visual presentation stream
- Target 1 (T1): Letter in white that participant needs to ID
- T2: Number that participant needs to ID
- Distractors: Letters between
- Lag: Distance between targets
![[Screenshot 2025-02-27 at 1.17.42 PM.png|300]]
- Healthy participants (black line) show "attnl blink": If T2 is presented 200-400 ms after T1, we have greater difficulty IDing – theory, limitation in brains resources to ID target after just IDing
- *Hypothesis*: PPCS blue line
**Study**
Pictures instead of words for eco validity
T1: pain or neutral face
T2: bird,flower,furniture
Distractors: scrambled/pixels

##### Gaze/eye tracking task
Simulates eye-tracking w/ mouse movement
Side by side images with overlay
a) Neutral, General threat, concussion threat - b) Neutral 
general threat = natural disaster, fire, concussion threat = someone getting hit in head, MRI

#### Results - not sig. 
No diff in attnl blink for neutral or pain face
As expected: saw attnl blink for PPCS + recovered for pain faces, but did not see any diff btwn groups 
Sensitivity analysis: regrouped by fear avoidance rather than PPCS/recovered, still no sig. results

**Why not?**
- Task not sensitive enough
- Concussion images not threatening 
- Participants too removed from injury 
- Pain faces insufficiently relevant
- More complex processes

*Barriers to the implementation of new cogn paradigms into clinical practice*
- psychometric prop. 
- determining relative util
- disciriminant and predictive val
- cooperation across fields

## Class 11 - Classifying Obj and predicting perception

> [!example] Today:
> - Passingham Ch. 2
> - Selecting attn. 
> - Stim similarity in LOC
> - Reading: Egner, Monti, Summerfield 2009


***Review***
- Preference in LOC for whole obj 
- Adaptive suppression in LOC for diff angles of obj

*Discussion*
- *Difference between recogn an obj and making sense of it?*
- *How is classifying an obj a form of making sense of it?*

### Inferotemporal cortex/Ventral visual system (IT)
- Important for obj categorization – *semantic* meaning of obj

Ventral visual sys (IT) categorizes obj at diff lvls:
- Superordinate, basic, subordinate, exemplar
	- Obama ex.: animate/face/man/president

#### Encoding approaches: divisions and hierarchies
Superordinate → exemplar: largest → smallest brain area (>1cm → < mm)

> It is not enough simply to recognize what we see; we also have to make sense of it. This involves classifying things, whether animate or inanimate... 
> *Passingham, Ch. 2*



##### Categorizing bugs, birds & mammals
- How are finer grained distinctions rep? 
- Prev research: funcitonal landmarks (*Animate/inanimate distinctions in IT- Grill-Spector*: Diff areas light up)
- Less known about finer distinctions
	- Diff classes of animal
- **Goal**: look at pattterns across voxels (**RSA**) to look for *similarity structures* at the level of biological class

*RSA review*
- Comparing patterns of representation, shared representational space

**fMRI experimental design**
- *Simple recognition memory task
- *Rate stimulus simularity*

"12 young adults participated in an fMRI study. As they lay there in the scanner in each trial they’d see 6 different series of 3 pictures of animals of the same class of animal -- either bugs or birds or primates. Then they would be shown one of those 6 series of 3 stimuli and would have to say if it was the same or different from what they saw in the previous trial. This probe question was just to keep the participants paying attention -- the experimenters didn't really care about how well they remembered the items. Here are some examples of the stimuli which were either bugs, birds & primates. *1) Afterwards they had participants rate how similar all of the different stimuli were to each other* and also do a task where they’d *2) see three and choose the one that wasn’t categorically like the others*. In this case they did care about the participants' choices because they wanted to know how similar or different they thought the different stimuli were from each other."

**RSA Results: LOC & IT**
- Pattern of activity represents stimuli matching behavioral similarity ratings &  mirroring biological class structure

***→ Human neuroimaging reveals a "hierarchical category structure that mirrors biological class strucutre" in ventral visual stream***

##### Using encoding for brain mapping in LOC
- How does abstr rep of continuum from bug to primate literally map to brain space 
- Does map for primates vs bugs look like animate vs inanimate? 
- Lateral-medial org. 

![[Screenshot 2025-02-27 at 1.53.36 PM.png|300]]

***→ Primate vs bug very similar to animate vs inanimate*** 

**Brain maps categories from inanimate to animate**
- Animal categories rep. medial (inanimate) → lateral (animate)
	- Only one dimension of rep obj
- Using behav judgements as target, semantic structure–ways of categorizing animals–reflected strongly thruout LOC: how much "like us" an animal is maps on to medial-lateral
	- Formed early in development, kept into late dementia

#### What we have learned from fMRI

- *Encoding Approach*: Responses to object parts and then whole objects along moving along occipital cortex from EV to LOC 
- *Encoding Approach*: More invariant processing and more category specificity as we move along ventral stream. 
- *Decoding approach*: shows continuum of finer-grained categories. 
	- In the ventral stream it matches semantic judgments of animal class 
	- In LOC it is organized along a spectrum of inanimate (not like me!) to very animate (a lot like me!)
### Predictive Coding
*Intro: waking up from anaesthetic TEDx*
- Consciousness, animal consciousness, computer consciousness
- World vs self consciousness 
- Top-down/bottom-up processing
	- Predictive hallucinations

**The problems of perception**:
- Diff objects can produce same images (e.g. orange vs orange ball)
- Same obj can produce diff images (e.g. diff angles)

*Review: Feedforward Feature Based Models*
- = Bottom-up 

→ How do we decide what to interpret an ambiguous image as? Between hypotheses H1/H2, which both equally acccount for lower-lvl features? = **Top down info**

*von Helmhotz*: First to describe brain as "prediction machine"
Perception as unconscious inference
- Cause of sensation inferred via its effects

##### Step by step of predictive coding model











## Class 12 - 
[[Class12_365_2025_notes-2.pdf]]


